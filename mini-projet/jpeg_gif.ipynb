{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.fftpack import dct, idct\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'img_rgb.jpg'\n",
    "path1 = 'file.jpg'\n",
    "path2 = 'reconstiued222.jpg'\n",
    "imag = Image.open(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_details(path):\n",
    "    # Ouvrir l'image à partir du chemin donné\n",
    "    img = Image.open(path)\n",
    "    \n",
    "    # Obtenir la taille de l'image (largeur, hauteur)\n",
    "    size = img.size\n",
    "    \n",
    "    # Obtenir le format de l'image (JPEG, PNG, etc.)\n",
    "    format = img.format\n",
    "    \n",
    "    # Obtenir le mode de l'image (RGB, L, etc.)\n",
    "    mode = img.mode\n",
    "    \n",
    "    # Obtenir la résolution de l'image si disponible (en DPI)\n",
    "    resolution = img.info.get('dpi')\n",
    "    \n",
    "    # Calculer la définition de l'image (nombre total de pixels)\n",
    "    definition = size[0] * size[1]\n",
    "    \n",
    "    # Stocker également la taille originale de l'image\n",
    "    original_size = size\n",
    "    \n",
    "    # Si la résolution est disponible, ajuster la taille en fonction de la résolution\n",
    "    if resolution is not None:\n",
    "        size = (size[0] / resolution[0], size[1] / resolution[1])\n",
    "    else:\n",
    "        size = (0, 0)  # ou toute résolution par défaut que vous souhaitez utiliser\n",
    "    \n",
    "    # Obtenir la taille du fichier en kilobytes\n",
    "    file_size_kb = os.path.getsize(path) / 1000.0\n",
    "    \n",
    "    # Calculer le nombre total de bits de l'image\n",
    "    if mode == 'RGB':\n",
    "        total_bits = definition * 3 * img.bits\n",
    "    else:\n",
    "        total_bits = definition * img.bits\n",
    "    \n",
    "    # Convertir le nombre total de bits en kilobits\n",
    "    total_bits_kb = total_bits / (1024 * 8)\n",
    "    \n",
    "    # Calculer le taux de compression en pourcentage\n",
    "    compression_ratio = 100 * (1 - (file_size_kb / total_bits_kb))\n",
    "    \n",
    "    # Afficher les informations collectées avec les unités\n",
    "    print(\"Dimensions réelles:\", size, \"inches\")\n",
    "    print(\"Format:\", format)\n",
    "    print(\"Mode:\", mode)\n",
    "    print(\"Resolution:\", resolution, \"DPI\")\n",
    "    print(\"Définition 1:\", definition, \"pixels\")\n",
    "    print(\"Définition 2:\", original_size, \"pixels\")\n",
    "    print(\"Taille en mémoire avec compression:\", file_size_kb, \"kB\")\n",
    "    print(\"Taille réelle sans compression:\", total_bits_kb/1024, \"MB\")\n",
    "    print(\"Taux de compression: \", compression_ratio, \"%\")\n",
    "    \n",
    "    # Retourner toutes les informations collectées sous forme de tuple\n",
    "    return size, format, mode, resolution, definition, original_size, file_size_kb, total_bits_kb, compression_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions réelles: (4.2, 2.36) inches\n",
      "Format: JPEG\n",
      "Mode: RGB\n",
      "Resolution: (300, 300) DPI\n",
      "Définition 1: 892080 pixels\n",
      "Définition 2: (1260, 708) pixels\n",
      "Taille en mémoire avec compression: 111.596 kB\n",
      "Taille réelle sans compression: 2.5522613525390625 MB\n",
      "Taux de compression:  95.73004274653992 %\n"
     ]
    }
   ],
   "source": [
    "result = image_details('eren_rgb.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(original_path, modified_path):\n",
    "    # Ouvrir l'image originale depuis le chemin spécifié\n",
    "    img1 = Image.open(original_path)\n",
    "    \n",
    "    # Ouvrir l'image modifiée (reconstruite) depuis le chemin spécifié\n",
    "    img2 = Image.open(modified_path)\n",
    "    \n",
    "    # Déterminer le type d'image de l'image originale\n",
    "    img1_mode = img1.mode\n",
    "    \n",
    "    # Créer une figure et des sous-graphiques pour afficher les deux images côte à côte\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))  # Créer une figure avec une rangée et deux colonnes\n",
    "    fig.subplots_adjust(wspace=0.01)  # Ajuster l'espace entre les sous-graphiques\n",
    "    \n",
    "    # Afficher l'image originale dans le premier sous-graphique\n",
    "    if img1_mode == 'L':\n",
    "        axs[0].imshow(img1, cmap='gray')\n",
    "        axs[0].set_title('Image initiale (niveau de gris)')  # Définir le titre du premier sous-graphique\n",
    "    elif img1_mode == '1':\n",
    "        axs[0].imshow(img1, cmap='binary')\n",
    "        axs[0].set_title('Image initiale (binaire)')  # Définir le titre du premier sous-graphique\n",
    "    else:\n",
    "        axs[0].imshow(img1)\n",
    "        axs[0].set_title('Image initiale')  # Définir le titre du premier sous-graphique\n",
    "    axs[0].axis('off')  # Désactiver les axes du premier sous-graphique\n",
    "    \n",
    "    # Afficher l'image reconstruite dans le deuxième sous-graphique\n",
    "    if img1_mode == 'L':\n",
    "        axs[1].imshow(img2, cmap='gray')\n",
    "        axs[1].set_title('Image reconstruite (niveau de gris)')  # Définir le titre du deuxième sous-graphique\n",
    "    elif img1_mode == '1':\n",
    "        axs[1].imshow(img2, cmap='binary')\n",
    "        axs[1].set_title('Image reconstruite (binaire)')  # Définir le titre du deuxième sous-graphique\n",
    "    else:\n",
    "        axs[1].imshow(img2)\n",
    "        axs[1].set_title('Image reconstruite')  # Définir le titre du deuxième sous-graphique\n",
    "    axs[1].axis('off')  # Désactiver les axes du deuxième sous-graphique\n",
    "    \n",
    "    # Ajuster la disposition de la figure pour éviter les chevauchements\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # Afficher la figure avec les deux images\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_ycrcb(img):\n",
    "    rgb_image = np.array(img)\n",
    "    ycrcb_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2YCrCb)\n",
    "    return ycrcb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ycrcb_to_rgb(ycrcb_image):\n",
    "    ycrcb_image = np.array(ycrcb_image)\n",
    "    rgb_image = cv2.cvtColor(ycrcb_image, cv2.COLOR_YCrCb2RGB)\n",
    "    # Convert numpy array to PIL Image\n",
    "    rgb_image_pil = Image.fromarray(rgb_image)\n",
    "    # Save the PIL Image\n",
    "    return rgb_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_subdivision(image, taille_bloc):\n",
    "\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "    # Obtenir la largeur et la hauteur de l'image\n",
    "    largeur, hauteur = image.size\n",
    "\n",
    "    # Calculer le nombre de blocs en largeur et en hauteur\n",
    "    blocs_largeur = (largeur + taille_bloc - 1) // taille_bloc\n",
    "    blocs_hauteur = (hauteur + taille_bloc - 1) // taille_bloc\n",
    "\n",
    "    # Créer une nouvelle image avec les dimensions ajustées\n",
    "    nouvelle_largeur = blocs_largeur * taille_bloc\n",
    "    nouvelle_hauteur = blocs_hauteur * taille_bloc\n",
    "    nouvelle_image = Image.new(image.mode, (nouvelle_largeur, nouvelle_hauteur), color='black')\n",
    "    nouvelle_image.paste(image, (0, 0))\n",
    "\n",
    "    blocs = []\n",
    "    # Parcourir chaque bloc\n",
    "    for y in range(blocs_hauteur):\n",
    "        for x in range(blocs_largeur):\n",
    "            # Obtenir les coordonnées du coin supérieur gauche du bloc\n",
    "            coin_sup_gauche_x = x * taille_bloc\n",
    "            coin_sup_gauche_y = y * taille_bloc\n",
    "            # Obtenir les coordonnées du coin inférieur droit du bloc\n",
    "            coin_inf_droit_x = (x + 1) * taille_bloc\n",
    "            coin_inf_droit_y = (y + 1) * taille_bloc\n",
    "            # Extraire le bloc de l'image\n",
    "            bloc = nouvelle_image.crop((coin_sup_gauche_x, coin_sup_gauche_y, coin_inf_droit_x, coin_inf_droit_y))\n",
    "            blocs.append(bloc)\n",
    "    \n",
    "    return blocs, (largeur, hauteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image(blocs, taille_bloc, dimensions_originales):\n",
    "    largeur_orig, hauteur_orig = dimensions_originales\n",
    "    \n",
    "    # Créer une nouvelle image vide avec les dimensions originales\n",
    "    image_reconstituee = np.zeros((hauteur_orig, largeur_orig, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Parcourir chaque bloc et le placer à la position correspondante dans l'image reconstituée\n",
    "    idx = 0\n",
    "    for y in range(0, hauteur_orig, taille_bloc):\n",
    "        for x in range(0, largeur_orig, taille_bloc):\n",
    "            # Extraire le bloc de l'image reconstituée\n",
    "            bloc = blocs[idx]\n",
    "            idx += 1\n",
    "            # Convertir le bloc en tableau numpy\n",
    "            bloc_np = np.array(bloc, dtype=np.uint8)\n",
    "            \n",
    "            if bloc_np.shape[2] > bloc_np.shape[0]:\n",
    "                bloc_np = np.transpose(bloc_np, (2, 1, 0))\n",
    "            # Calculer les coordonnées de collage du bloc dans l'image reconstituée\n",
    "            x_end = min(x + taille_bloc, largeur_orig)\n",
    "            y_end = min(y + taille_bloc, hauteur_orig)\n",
    "            # Coller le bloc dans l'image reconstituée\n",
    "            image_reconstituee[y:y_end, x:x_end] = bloc_np[:y_end-y, :x_end-x]\n",
    "\n",
    "    # Créer une image PIL à partir du tableau numpy\n",
    "    image_reconstituee_pil = Image.fromarray(image_reconstituee)\n",
    "    \n",
    "    return image_reconstituee_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_subsampling(transcol, SSV, SSH):\n",
    "    # Convert Image to NumPy array\n",
    "    transcol_np = np.array(transcol)\n",
    "    \n",
    "    # Filtrage des canaux de chrominance\n",
    "    #crf = cv2.boxFilter(transcol_np[:,:,1], ddepth=-1, ksize=(2,2))\n",
    "    #cbf = cv2.boxFilter(transcol_np[:,:,2], ddepth=-1, ksize=(2,2))\n",
    "    \n",
    "    crf = transcol_np[:,:,1]\n",
    "    cbf = transcol_np[:,:,2]\n",
    "    \n",
    "    # Sous-échantillonnage des canaux de chrominance\n",
    "    crsub = crf[::SSV, ::SSH]\n",
    "    cbsub = cbf[::SSV, ::SSH]\n",
    "    \n",
    "    # Création de la liste contenant tous les canaux\n",
    "    imSub = [np.array(transcol_np[:,:,0]), np.array(crsub), np.array(cbsub)]\n",
    "    \n",
    "    return imSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_chroma_subsampling(imSub, SSV, SSH):\n",
    "    # Récupérer les canaux sous-échantillonnés\n",
    "    lum, _, _ = imSub\n",
    "    \n",
    "    # Initialiser des tableaux pour les canaux complets\n",
    "    H, W = imSub[1].shape\n",
    "    crf = np.zeros((H * SSH, W * SSV))\n",
    "    cbf = np.zeros((H * SSH, W * SSV))\n",
    "    \n",
    "    # Créer l'image complète\n",
    "    image_complete = np.zeros((H * SSV, W * SSH, 3), dtype=np.uint8)\n",
    "    image_complete[:,:,0] = lum\n",
    "    image_complete[:,:,1] = np.repeat(np.repeat(imSub[1], SSH, axis=0), SSV, axis=1)\n",
    "    image_complete[:,:,2] = np.repeat(np.repeat(imSub[2], SSH, axis=0), SSV, axis=1)\n",
    "    \n",
    "    # Convertir le tableau numpy en image PIL\n",
    "    transcol = Image.fromarray(image_complete)\n",
    "    \n",
    "    return transcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dct(matrix):\n",
    "    # Appliquer la DCT à chaque matrice\n",
    "    dct_matrice0 = dct(dct(matrix[0].T, norm='ortho').T, norm='ortho')\n",
    "    dct_matrice1 = dct(dct(matrix[1].T, norm='ortho').T, norm='ortho')\n",
    "    dct_matrice2 = dct(dct(matrix[2].T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "    dct_matrix = [dct_matrice0, dct_matrice1, dct_matrice2]\n",
    "    \n",
    "    return dct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dct(dct_matrix):\n",
    "    # Appliquer l'inverse de la DCT à chaque matrice\n",
    "    inverse_dct_matrice0 = idct(idct(dct_matrix[0].T, norm='ortho').T, norm='ortho')\n",
    "    inverse_dct_matrice1 = idct(idct(dct_matrix[1].T, norm='ortho').T, norm='ortho')\n",
    "    inverse_dct_matrice2 = idct(idct(dct_matrix[2].T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "    inverse_dct_matrix = [inverse_dct_matrice0, inverse_dct_matrice1, inverse_dct_matrice2]\n",
    "    \n",
    "    return inverse_dct_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_average(matrix1):\n",
    "        # Redimensionne la matrice en une matrice 4x4 en prenant la moyenne de chaque bloc 2x2\n",
    "        reshaped = np.zeros((4, 4))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                # Calcule la moyenne des 4 valeurs dans le bloc 2x2\n",
    "                block_mean = np.mean(matrix1[2*i:2*(i+1), 2*j:2*(j+1)])\n",
    "                reshaped[i, j] = block_mean\n",
    "        return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization(matrix):\n",
    "    # Récupération des composantes de l'image à partir de la liste\n",
    "    luminance = matrix[0]  # Composante de luminance (Y)\n",
    "    chrominance_U = matrix[1]\n",
    "    chrominance_V = matrix[2]\n",
    "    \n",
    "    # Réplication des échantillons pour chaque bloc 2x2\n",
    "    Cr = np.kron(chrominance_U, np.ones((2, 2)))\n",
    "    Cb = np.kron(chrominance_V, np.ones((2, 2)))\n",
    "    \n",
    "    # Matrices de quantification de luminance et de chrominance\n",
    "    luminance_quantization_matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                              [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                              [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                              [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                              [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                              [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                              [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                              [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "\n",
    "    chrominance_quantization_matrix = np.array([[17, 18, 24, 47, 99, 99, 99, 99],\n",
    "                                                [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "                                                [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "                                                [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99]])\n",
    "    \n",
    "    # Applique les matrices de quantification à chaque composante\n",
    "    luminance_quantized = np.round(luminance / luminance_quantization_matrix)\n",
    "    chrominance_Cr_quantized = np.round(Cr / chrominance_quantization_matrix)\n",
    "    chrominance_Cb_quantized = np.round(Cb / chrominance_quantization_matrix)\n",
    "    \n",
    "    chrominance_Cr_quantized = np.round(reshape_and_average(chrominance_Cr_quantized))\n",
    "    chrominance_Cb_quantized = np.round(reshape_and_average(chrominance_Cb_quantized))\n",
    "    \n",
    "    quantized = [luminance_quantized, chrominance_Cr_quantized, chrominance_Cb_quantized]\n",
    "    \n",
    "    return quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization(matrix):\n",
    "    # Récupération des composantes de l'image à partir de la liste\n",
    "    L = matrix[0]  # Composante de luminance (Y)\n",
    "    chrominance_Cr_quantized = matrix[1]\n",
    "    chrominance_Cb_quantized = matrix[2]\n",
    "    \n",
    "    # Réplication des échantillons pour chaque bloc 2x2\n",
    "    Cr = np.kron(chrominance_Cr_quantized, np.ones((2, 2)))\n",
    "    Cb = np.kron(chrominance_Cb_quantized, np.ones((2, 2)))\n",
    "\n",
    "    # Matrices de quantification de luminance et de chrominance\n",
    "    luminance_quantization_matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                              [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                              [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                              [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                              [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                              [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                              [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                              [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "\n",
    "    chrominance_quantization_matrix = np.array([[17, 18, 24, 47, 99, 99, 99, 99],\n",
    "                                                [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "                                                [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "                                                [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "                                                [99, 99, 99, 99, 99, 99, 99, 99]])\n",
    "\n",
    "    # Multiplie chaque valeur quantifiée par sa correspondance dans la matrice de quantification respective\n",
    "    luminance_dequantized = L * luminance_quantization_matrix\n",
    "    chrominance_Cr_dequantized = Cr * chrominance_quantization_matrix\n",
    "    chrominance_Cb_dequantized = Cb * chrominance_quantization_matrix\n",
    "\n",
    "    # Restaure la résolution de chrominance U et V à 8x8\n",
    "    chrominance_Cr_dequantized = reshape_and_average(chrominance_Cr_dequantized)\n",
    "    chrominance_Cb_dequantized = reshape_and_average(chrominance_Cb_dequantized)\n",
    "\n",
    "    # Retourne la liste des composantes [luminance, chrominance_U, chrominance_V]\n",
    "    dequantized = [luminance_dequantized, chrominance_Cr_dequantized, chrominance_Cb_dequantized]\n",
    "\n",
    "    return dequantized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_scan(matrix):\n",
    "    Y = np.array(matrix[0], dtype=np.float64)\n",
    "    Cr = np.array(matrix[1], dtype=np.float64)\n",
    "    Cb = np.array(matrix[2], dtype=np.float64)\n",
    "\n",
    "    Y = np.concatenate([np.diagonal(Y[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1 - Y.shape[0], Y.shape[0])])\n",
    "    Cr = np.concatenate([np.diagonal(Cr[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1 - Cr.shape[0], Cr.shape[0])])\n",
    "    Cb = np.concatenate([np.diagonal(Cb[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1 - Cb.shape[0], Cb.shape[0])])\n",
    "    \n",
    "    ycrcb = np.concatenate((Y, Cr, Cb))\n",
    "    return ycrcb.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_zigzag_scan(ycrcb):\n",
    "    def inverse_vecteur_zigzag(vector, shape):\n",
    "        # Initialiser une matrice avec des valeurs nulles\n",
    "        rows, cols = shape\n",
    "        mat = np.array([[None] * cols for _ in range(rows)], dtype=np.float64)\n",
    "        row, col = 0, 0\n",
    "        direction = 1\n",
    "\n",
    "        # Remplir la matrice en suivant le modèle de balayage en zigzag\n",
    "        for i in range(rows * cols):\n",
    "            mat[row][col] = vector[i]\n",
    "            if direction == 1:\n",
    "                if col == cols - 1:\n",
    "                    row += 1\n",
    "                    direction = -1\n",
    "                elif row == 0:\n",
    "                    col += 1\n",
    "                    direction = -1\n",
    "                else:\n",
    "                    row -= 1\n",
    "                    col += 1\n",
    "            else:\n",
    "                if row == rows - 1:\n",
    "                    col += 1\n",
    "                    direction = 1\n",
    "                elif col == 0:\n",
    "                    row += 1\n",
    "                    direction = 1\n",
    "                else:\n",
    "                    row += 1\n",
    "                    col -= 1\n",
    "\n",
    "        return mat\n",
    "    \n",
    "    def diviser_liste(liste):\n",
    "        # Vérifier si la liste a au moins 96 éléments\n",
    "        if len(liste) < 96:\n",
    "            return \"La liste doit contenir au moins 95 éléments pour être divisée selon les spécifications.\"\n",
    "        \n",
    "        # Diviser la liste en trois parties\n",
    "        premiere_partie = liste[:64]\n",
    "        deuxieme_partie = liste[64:80]\n",
    "        troisieme_partie = liste[80:]\n",
    "\n",
    "        return premiere_partie, deuxieme_partie, troisieme_partie\n",
    "    \n",
    "    # Séparer les composantes Y, Cr et Cb\n",
    "    Y, Cr, Cb = diviser_liste(ycrcb)\n",
    "    \n",
    "    # Appliquer la fonction inverse de balayage en zigzag à chaque composante\n",
    "    Y = inverse_vecteur_zigzag(Y, (8, 8))\n",
    "    Cr = inverse_vecteur_zigzag(Cr, (4, 4))\n",
    "    Cb = inverse_vecteur_zigzag(Cb, (4, 4))\n",
    "    \n",
    "    # Arrondir les valeurs\n",
    "    Y = np.round(Y)\n",
    "    Cr = np.round(Cr)\n",
    "    Cb = np.round(Cb)\n",
    "    \n",
    "    return [Y, Cr, Cb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(data):\n",
    "    encoded_data = \"\"\n",
    "    current_char = data[0]\n",
    "    count = 1\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == current_char:\n",
    "            count += 1\n",
    "        else:\n",
    "            if count > 1:  # Ajout de cette condition\n",
    "                encoded_data += str(current_char) + \"_\" + str(count) + \"*\"\n",
    "            else:\n",
    "                encoded_data += str(current_char) + \"*\"\n",
    "            current_char = data[i]\n",
    "            count = 1\n",
    "\n",
    "    if count > 1:  # Ajout de cette condition\n",
    "        encoded_data += str(current_char) + \"_\" + str(count)\n",
    "    else:\n",
    "        encoded_data += str(current_char)\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(encoded_data):\n",
    "    decoded_data = []\n",
    "    encoded_data_split = encoded_data.split('*')\n",
    "\n",
    "    for item in encoded_data_split:\n",
    "        if \"_\" in item:\n",
    "            char, count = item.split(\"_\")\n",
    "            char = float(char)\n",
    "            if char.is_integer():\n",
    "                char = int(char)\n",
    "            decoded_data.extend([char] * int(count))\n",
    "        else:\n",
    "            char = float(item)\n",
    "            if char.is_integer():\n",
    "                char = int(char)\n",
    "            decoded_data.append(char)\n",
    "\n",
    "    return decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_chr(chaine):\n",
    "    occ = {c: chaine.count(c) for c in set(chaine)}\n",
    "    return sorted(occ.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Fonction principale implémentant le codage de Huffman\n",
    "def huffman_dictionnary_code(node, binString=''):\n",
    "    if isinstance(node, str):\n",
    "        return {node: binString}\n",
    "    (l, r) = node\n",
    "    d = {}\n",
    "    d.update(huffman_dictionnary_code(l, binString + '0'))\n",
    "    d.update(huffman_dictionnary_code(r, binString + '1'))\n",
    "    return d\n",
    "\n",
    "# Construction de l'arbre de Huffman\n",
    "def huffman_tree(chaine):\n",
    "    nodes = ext_chr(chaine)\n",
    "    \n",
    "    while len(nodes) > 1:\n",
    "        (key1, c1) = nodes.pop()\n",
    "        (key2, c2) = nodes.pop()\n",
    "        node = (key1, key2)\n",
    "        nodes.append((node, c1 + c2))\n",
    "        nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return nodes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_huffman(string):\n",
    "    nodes = huffman_tree(string)\n",
    "    huffmanCode = huffman_dictionnary_code(nodes)\n",
    "    \n",
    "    compressed_string = ''\n",
    "    for char in string:\n",
    "        compressed_string += huffmanCode[char]\n",
    "    return compressed_string, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_huffman(compressed_string, huffman_tree):\n",
    "    decoded_string = ''\n",
    "    current_node = huffman_tree\n",
    "    \n",
    "    for bit in compressed_string:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]\n",
    "        else:\n",
    "            current_node = current_node[1]\n",
    "        \n",
    "        if isinstance(current_node, str):\n",
    "            decoded_string += current_node\n",
    "            current_node = huffman_tree\n",
    "    \n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diviser_longue_chaine(chaine, tailles_sous_chaines):\n",
    "    sous_chaines = []\n",
    "    index_debut = 0\n",
    "    for taille in tailles_sous_chaines:\n",
    "        sous_chaine = chaine[index_debut:index_debut+taille]\n",
    "        sous_chaines.append(sous_chaine)\n",
    "        index_debut += taille\n",
    "    return sous_chaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_huffman_codes(strings):\n",
    "  compressed_string = ''\n",
    "  huffman_trees = []\n",
    "  huffman_code_lengths = []\n",
    "  \n",
    "  for code in strings:\n",
    "    compressed_string += encoding_huffman(code)[0]\n",
    "    huffman_trees.append(encoding_huffman(code)[1])\n",
    "    huffman_code_lengths.append(len(encoding_huffman(code)[0]))\n",
    "\n",
    "  return compressed_string, huffman_trees, huffman_code_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconcatenate_huffman_codes(compressed_string, huffman_trees, huffman_code_lengths):\n",
    "    # Divise la chaîne compressée en sous-chaînes\n",
    "    liste = diviser_longue_chaine(compressed_string, huffman_code_lengths)\n",
    "    decoded = []\n",
    "    \n",
    "    for i in range(len(liste)):\n",
    "        # Décode chaque sous-chaîne en utilisant l'arbre Huffman correspondant\n",
    "        elt = decoding_huffman(liste[i], huffman_trees[i])\n",
    "        decoded.append(elt)\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour la compression intermédiaire JPEG\n",
    "def intermediate_jpeg_compression(image):\n",
    "    # Chaîne de compression\n",
    "    compressed_data = ''\n",
    "    \n",
    "    # Conversion de l'image RGB en espace de couleur YCrCb\n",
    "    ycrcb_code = rgb_to_ycrcb(image)\n",
    "    \n",
    "    # Sous-division de l'image en blocs de 8x8 et récupération de la forme originale\n",
    "    sub_blocks, original_shape = block_subdivision(ycrcb_code, 8)\n",
    "    \n",
    "    # Liste pour stocker les codes compressés de chaque bloc\n",
    "    compressed_blocks = []\n",
    "    \n",
    "    # Pour chaque bloc de sous-division\n",
    "    for block in sub_blocks:\n",
    "        # Sous-échantillonnage des composantes Chroma (Cr, Cb) par un facteur de 2x2\n",
    "        sub_sampled_block = chroma_subsampling(block, 2, 2)\n",
    "        \n",
    "        # Application de la transformée en cosinus discrète (DCT) au bloc\n",
    "        dct_transformed_block = apply_dct(sub_sampled_block)\n",
    "        \n",
    "        # Quantification des coefficients DCT\n",
    "        quantized_block = quantization(dct_transformed_block)\n",
    "        \n",
    "        # Balayage zigzag des coefficients quantifiés\n",
    "        zigzag_scanned_block = zigzag_scan(quantized_block)\n",
    "        \n",
    "        # Codage RLE des coefficients balayés en zigzag\n",
    "        rle_encoded_block = rle_encode(zigzag_scanned_block)\n",
    "        \n",
    "        # Ajout du code compressé du bloc à la liste\n",
    "        compressed_blocks.append(rle_encoded_block)\n",
    "    \n",
    "    # Concaténation des codes Huffman des blocs\n",
    "    compressed_data, huffman_trees, code_lengths = concatenate_huffman_codes(compressed_blocks)\n",
    "    \n",
    "    return compressed_data, huffman_trees, code_lengths, original_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour la décompression intermédiaire JPEG\n",
    "def intermediate_jpeg_decompression(compressed_data, huffman_trees, code_lengths, original_shape):\n",
    "    # Déconcaténation des codes Huffman\n",
    "    huffman_decoded_blocks = deconcatenate_huffman_codes(compressed_data, huffman_trees, code_lengths)\n",
    "    \n",
    "    # Liste pour stocker les blocs décompressés\n",
    "    decompressed_blocks = []\n",
    "    \n",
    "    # Pour chaque bloc décodé\n",
    "    for block in huffman_decoded_blocks:\n",
    "        # Décodage RLE\n",
    "        rle_decoded_block = rle_decode(block)\n",
    "        \n",
    "        # Reconstruction du balayage zigzag\n",
    "        zigzag_scanned_block = inverse_zigzag_scan(rle_decoded_block)\n",
    "        \n",
    "        # Déquantification des coefficients\n",
    "        dequantized_block = dequantization(zigzag_scanned_block)\n",
    "        \n",
    "        # Transformation inverse de la DCT\n",
    "        inverse_dct_block = inverse_dct(dequantized_block)\n",
    "        \n",
    "        # Reconstruction du sous-échantillonnage\n",
    "        inverse_subsampled_block = inverse_chroma_subsampling(inverse_dct_block, 2, 2)\n",
    "        \n",
    "        # Ajout du bloc décompressé à la liste\n",
    "        decompressed_blocks.append(inverse_subsampled_block)\n",
    "    \n",
    "    # Reconstitution de l'image à partir des blocs décompressés\n",
    "    reconstructed_image = reconstruct_image(decompressed_blocks, 8, original_shape)\n",
    "    \n",
    "    # Conversion de l'espace de couleur YCrCb en RGB\n",
    "    rgb_image = ycrcb_to_rgb(reconstructed_image)\n",
    "    \n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_palette(image, num_colors):\n",
    "    image = np.array(image)\n",
    "    # Convertir l'image en un tableau 2D de pixels\n",
    "    pixels = np.reshape(image, (-1, 3))  # (nombre de pixels, 3 canaux de couleur)\n",
    "\n",
    "    # Appliquer l'algorithme de k-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Obtenir les centres des clusters (couleurs dominantes)\n",
    "    color_palette = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    # Associer chaque pixel à l'indice de couleur dans la palette\n",
    "    labels = kmeans.predict(pixels)\n",
    "\n",
    "    # Reformater les indices des couleurs dans la palette selon la forme de l'image originale\n",
    "    palette_indices = np.reshape(labels, image.shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_color_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_palette(image, color_palette):\n",
    "    image = np.array(image)\n",
    "    pixels = np.reshape(image, (-1, 3))  # (nombre de pixels, 3 canaux de couleur)\n",
    "\n",
    "    # Calculer la distance de chaque pixel à chaque couleur de la palette\n",
    "    distances = np.linalg.norm(pixels[:, np.newaxis] - color_palette, axis=2)\n",
    "\n",
    "    # Obtenir l'indice de la couleur la plus proche pour chaque pixel\n",
    "    indices = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Reformater les indices des couleurs selon la forme de l'image originale\n",
    "    mapped_indices = np.reshape(indices, image.shape[:2])\n",
    "\n",
    "    return mapped_indices.flatten(), np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_map_to_palette(mapped_indices, color_palette, image_shape):\n",
    "    # Convertir les indices mappés en tableau NumPy si ce n'est pas déjà le cas\n",
    "    mapped_indices = np.asarray(mapped_indices)\n",
    "\n",
    "    # Réorganiser les couleurs de la palette en fonction des indices mappés\n",
    "    image_colors = color_palette[mapped_indices]\n",
    "\n",
    "    # Reformater les couleurs en une image selon la forme donnée\n",
    "    reconstructed_image = np.reshape(image_colors, image_shape)\n",
    "\n",
    "    return reconstructed_image, color_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionner2(liste):\n",
    "    tailles = []\n",
    "    nombres_fusionnes = \"\"\n",
    "    \n",
    "    # Parcourir tous les éléments de la liste\n",
    "    for nombre in liste:\n",
    "        # Convertir chaque nombre en chaîne de caractères et l'ajouter à la chaîne fusionnée\n",
    "        nombres_fusionnes += str(nombre)\n",
    "        \n",
    "        # Ajouter la taille de l'élément à la liste des tailles\n",
    "        tailles.append(len(str(nombre)))\n",
    "    \n",
    "    # Retourner la chaîne de caractères fusionnée et la liste des tailles\n",
    "    return nombres_fusionnes, tailles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separer2(chaine, tailles):\n",
    "    nombres = []\n",
    "    debut = 0\n",
    "    \n",
    "    # Parcourir toutes les tailles dans la liste\n",
    "    for taille in tailles:\n",
    "        # Extraire le sous-chaîne correspondant à la taille actuelle\n",
    "        sous_chaine = chaine[debut:debut+taille]\n",
    "        \n",
    "        # Convertir la sous-chaîne en nombre et l'ajouter à la liste des nombres\n",
    "        nombres.append(int(sous_chaine))\n",
    "        \n",
    "        # Mettre à jour la position de départ pour la prochaine sous-chaîne\n",
    "        debut += taille\n",
    "    \n",
    "    # Retourner la liste des nombres\n",
    "    return nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_lzw(data, color_palette):\n",
    "    alphabet = [str(i) for i in range(len(color_palette))]\n",
    "    data_fused, taille = fusionner2(data)  # Fusionner les chaînes de caractères\n",
    "    encoded_data = []\n",
    "\n",
    "    dictionary = {}  # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[char] = i\n",
    "\n",
    "    prefix = ''\n",
    "    for char in data_fused:\n",
    "        new_entry = prefix + char\n",
    "        if new_entry in dictionary:\n",
    "            prefix = new_entry\n",
    "        else:\n",
    "            encoded_data.append(dictionary[prefix])\n",
    "            dictionary[new_entry] = len(dictionary)\n",
    "            prefix = char\n",
    "\n",
    "    if prefix:\n",
    "        encoded_data.append(dictionary[prefix])\n",
    "\n",
    "    return encoded_data, taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_lzw(compressed_data, color_palette, tailleL):\n",
    "    alphabet = [str(i) for i in range(len(color_palette))]\n",
    "    result = []\n",
    "    dictionary = {}\n",
    "    current_code = len(alphabet)\n",
    "\n",
    "    # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[i] = char\n",
    "\n",
    "    old_entry = dictionary[compressed_data[0]]\n",
    "    result.append(old_entry)\n",
    "    for new_entry in compressed_data[1:]:\n",
    "        if new_entry in dictionary:\n",
    "            entry = dictionary[new_entry]\n",
    "        elif new_entry == current_code:\n",
    "            entry = old_entry + old_entry[0]\n",
    "        else:\n",
    "            raise ValueError(\"Mauvaise séquence compressée\")\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "        # Utilisez le même dictionnaire pour la décompression\n",
    "        dictionary[current_code] = old_entry + entry[0]\n",
    "        current_code += 1\n",
    "        old_entry = entry\n",
    "\n",
    "    result = ''.join(result)\n",
    "    result = separer2(result, tailleL)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaire_compression_gif(image, num_colors):\n",
    "    color_palette, palette_indices = create_color_palette(image, num_colors)\n",
    "    mapper, shape = map_to_palette(image, color_palette)\n",
    "    compressed_data, taille = encoding_lzw(mapper, color_palette)\n",
    "    \n",
    "    return compressed_data, color_palette, palette_indices, shape, taille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaire_decompression_gif(compressed_data, color_palette, palette_indices, shape, taille):\n",
    "    # Décompression LZW\n",
    "    code1 = decoding_lzw(compressed_data, color_palette, taille)\n",
    "    _, color_palette1 = inverse_map_to_palette(code1, color_palette, shape)\n",
    "    code3 = inverse_color_palette(color_palette1, palette_indices)\n",
    "    image = Image.fromarray(code3)  # Convertir le tableau NumPy en objet Image PIL\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
