------------------------------- COMPRESSION JPEG ----------------------------------

1. Prétraitement : Nous commençons par extraire la/les matrice(s) de pixels de l'image RGB. Cette opération est réalisée après l'ouverture du fichier, par exemple avec `Image.open()`, suivie de sa conversion en un tableau numpy via `numpy.array(Image.open())` en utilisant le langage de programmation Python. Tout traitement ultérieur de l'image sous forme matricielle agit sur les pixels, qui sont les coefficients des matrices représentant l'image.

2. Changement d'espace de couleur : Cette étape permet une compression plus efficace tout en préservant la qualité visuelle de l'image.

3. Subdivision de l'image en blocs : Le bloc de matrice(s) de pixels de taille L x C est découpé en blocs de 8 * 8 pixels. Cette taille facilite la manipulation de l'image originale et correspond à la taille requise pour la matrice de quantification. Si le nombre de lignes L et/ou de colonnes C n'est pas un multiple de 8, des pixels supplémentaires sont ajoutés avec des valeurs nulles.

4. Sous-échantillonnage : La méthode la plus souvent utilisée pour cette étape est le sous-échantillonnage des matrices Cr et Cb en 4:2:0. Cette méthode réduit les matrices de chrominance Cr et Cb en matrices 4 * 4 en sélectionnant les pixels de positions impaires horizontalement et verticalement. Par la suite, chaque bloc 8 * 8 de la matrice de luminance est associé à des blocs 4 * 4 de ces nouvelles matrices chrominances. Cette réduction de données ne s'applique qu'aux composantes de chrominance car l'œil est moins sensible à ces variations par rapport à la luminance, ce qui permet de diminuer la quantité de données tout en conservant une bonne qualité d'image et une taille réduite.

5. Application de la DCT (Transformée en Cosinus Discrète) : La DCT, dérivée de la transformée de Fourier, réorganise l'information de manière à concentrer la plupart de l'énergie de l'image dans un petit nombre de coefficients. En d'autres termes, elle sépare les composantes d'une image en une partie significative et une partie négligeable. La DCT transforme l'information spatiale d'une image en une représentation fréquentielle plus compacte, facilitant ainsi la compression tout en préservant une qualité visuelle acceptable.

6. Quantification : Après la DCT, la matrice résultante est quantifiée pour chaque plan de luminance et de chrominance par une matrice spécifique prédéfinie. Les matrices de quantification (celle de la luminance et celle des chrominances) étant de taille 8 * 8 et celles de chrominances obtenues lors de l'étape de sous-échantillonnage étant de taille 4 * 4, ces dernières sont étendues de telle sorte à dupliquer chaque coefficient de la matrice comme une matrice 2 * 2. Ainsi, nous obtenons une matrice 8 * 8 dont chaque 2 * 2 pixels sont identiques, permettant ainsi l'étape de quantification sur les matrices chrominances. La compression JPEG est avec perte principalement en raison de cette étape. La matrice de quantification divise la matrice de la DCT et arrondit les valeurs, ce qui conduit à une matrice avec peu de valeurs différentes de zéro dans la partie supérieure gauche et des zéros pour le reste de la matrice. Lors de la décompression, la multiplication de cette matrice quantifiée par celle de la quantification laisse les valeurs à zéro. Ainsi, il est impossible de revenir exactement aux données initiales, mais l'information est néanmoins conservée. Par la suite, les matrices chrominances redeviennent des matrices 4 * 4 en faisant la moyenne de chaque 2 * 2 pixels (à l'image de la manière dont elles ont été étendues).

7. Parcours des matrices : Pendant cette étape, nous utilisons le parcours en zigzag, qui, grâce à la disposition de la nouvelle matrice, maximise les répétitions, favorisant ainsi le codage RLE.

8. Codage RLE : Après le parcours en zigzag, les vecteurs résultants sont codés par RLE pour réduire la taille de l'information et des données sans perdre aucune information.

9. Codage Huffman : Enfin, le codage de Huffman est appliqué au résultat du codage RLE. À l'issue de cette étape, nous obtenons l'image compressée qui, avec l'en-tête, constitue notre fichier image complet compressé avec perte, tout en conservant les informations essentielles pour la visualisation.

------------------------------- COMPRESSION GIF ----------------------------------

1. Extraction de la/des matrice(s) de pixels de l'image RGB : Cette opération est réalisée après l'ouverture du fichier, par exemple avec `Image.open()`, suivie de sa conversion en un tableau numpy via `numpy.array(Image.open())`. Tout traitement ultérieur de l'image sous forme matricielle agit sur les pixels, qui sont les coefficients des matrices représentant l'image.

2. Création de la palette de couleur : La création de palettes est l'une des principales caractéristiques de cette méthode de compression d'image. Le k-means clustering, qui est la méthode de création de palette la plus utilisée pour cette méthode de compression, consiste à choisir au hasard comme centroïdes parmi les pixels (les combinaisons de couleurs [rouge, vert, bleu]), un nombre égal à celui de la palette de couleur demandée. Après cette sélection aléatoire de ces centroïdes, des clusters sont déterminés pour chaque centroïde en calculant la distance entre les valeurs des pixels de l'image et celui de tous les centroïdes, puis en associant le pixel au centroïde avec lequel la distance est la plus faible. Un cluster désigne l'ensemble des pixels associés à un centroïde pendant une itération donnée. Après avoir déterminé tous les clusters de tous les centroïdes, les centroïdes sont mis à jour en calculant la moyenne par canal (couleur) des clusters qui lui sont associés. Ensuite, ce processus est répété jusqu'à obtenir une certaine valeur de tolérance, un nombre maximal d'itérations ou une convergence des centroïdes. Ainsi, la palette de couleurs à 2^n valeurs distinctes est créée.

3. Le mappage : il s'agit de l'association de chaque pixel de l'image à une couleur (un élément) de la palette de couleurs (un centroïde). Ainsi, au lieu que les pixels soient représentés par les 3 composantes [rouge, vert, bleu], ils seront représentés par des index de la palette de couleurs (les centroïdes) allant généralement de 0 à 2^n - 1. Ce mappage est réalisé en calculant la distance euclidienne entre les valeurs de chaque pixel pix[i] et celles de tous les éléments de la palette de couleurs pal[j]. Par la suite, le pixel prend l'index de l'élément de la palette de couleurs avec lequel la distance est la plus faible.

4. Passage de la matrice au vecteur : Ensuite, nous changeons la matrice en vecteur selon le parcours en ligne, en colonne ou en zigzag. Cette étape est facultative mais elle donne une représentation plus compacte de l'image et permet une facilité de la manipulation et du traitement des données.

5. Codage par LZW : Enfin vient l'étape du codage LZW. Le codage par l'algorithme de Lempel-Ziv-Welch est la dernière étape du processus de compression GIF. Ce codage se base sur l'existence d'une table de code (ici notre palette de couleurs (centroïdes) qui représente le dictionnaire). À la fin de cette étape, nous obtenons le fichier compressé qui, avec les données de l'en-tête portant les informations sur le fichier et comment le décompresser, permet de remonter à l'image initiale avec les mêmes données et la même information.
