{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Importation$ $des$ $bibliothèques$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/issa-sangare/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.fftpack import dct, idct\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Données/Informations$ $utilisées$ $pour$ $le$ $programme$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '3.jpeg'\n",
    "path1 = 'file.txt'\n",
    "path2 = 'reconstiued3.jpg'\n",
    "num_rows = 4\n",
    "num_colors = 64\n",
    "num_blocs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Caratéristiques$ $de$ $l'image$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details(path):\n",
    "    img = Image.open(path)\n",
    "    size = img.size\n",
    "    format = img.format\n",
    "    mode = img.mode\n",
    "    resolution = img.info.get('dpi')\n",
    "    definition = size[0] * size[1]\n",
    "    definition2 = size\n",
    "    \n",
    "    if resolution is not None:\n",
    "        size = (size[0]/ resolution[0], size[1] / resolution[1])\n",
    "    else:\n",
    "        size = (0, 0)  # or any default resolution you want to use\n",
    "    \n",
    "    poids = os.path.getsize(path) / (1000.0)  # Convert to kilobytes\n",
    "    \n",
    "    if mode == 'RGB':\n",
    "        trsc = definition * 3 * img.bits\n",
    "    else:\n",
    "        trsc = definition * 1 * img.bits\n",
    "    \n",
    "    trsc /= (1024 * 8)\n",
    "    \n",
    "    taux_compression = 100 * (1 - (poids/trsc))\n",
    "        \n",
    "    return size, format, mode, resolution, definition, definition2, poids, trsc, taux_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (inch): (4.2, 2.36)\n",
      "Format: JPEG\n",
      "Mode: RGB\n",
      "Resolution: (300, 300)\n",
      "Definition (pixels): 892080\n",
      "Définition (L * C): (1260, 708)\n",
      "Taille en mémoire avec compression: 113.617 KB\n",
      "Taille réelle sans compression: 2.5522613525390625 MB\n",
      "Taux de compression:  95.65271395689476 %\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "result = details(path)\n",
    "print(\"Size (inch):\", result[0])\n",
    "print(\"Format:\", result[1])\n",
    "print(\"Mode:\", result[2])\n",
    "print(\"Resolution:\", result[3])\n",
    "print(\"Definition (pixels):\", result[4])\n",
    "print(\"Définition (L * C):\", result[5])\n",
    "print(\"Taille en mémoire avec compression:\", result[6], \"KB\")\n",
    "print(\"Taille réelle sans compression:\", result[7]/1024, \"MB\")\n",
    "print(\"Taux de compression: \", result[8], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Affichage$ $de$ $la$ $palette$ $de$ $couleurs$ $et$ $des$ $images$ $avant$ $et$ $après$ $application$ $de$ $la$ $palette$ $de$ $couleurs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_palette(image, color_palette, palette_indices, num_rows):\n",
    "    num_colors = len(color_palette)\n",
    "    num_cols = num_colors // num_rows\n",
    "\n",
    "    image_with_palette = color_palette[palette_indices]\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    for i, color in enumerate(color_palette):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        color_patch = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        color_patch[:, :] = color\n",
    "        plt.imshow(color_patch)\n",
    "        plt.title(f'Couleur {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Palette de couleurs', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))\n",
    "    fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Image originale')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(image_with_palette)\n",
    "    axs[1].set_title(f'Image avec la palette de {num_colors} couleurs')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Affichage$ $de$ $deux$ $images$ $quelconques$ $côte$ $à$ $côte$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(reconstructed_image, image1, num_colors):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))\n",
    "    fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "    axs[0].imshow(reconstructed_image)\n",
    "    axs[0].set_title('Image reconstruite')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(image1)\n",
    "    axs[1].set_title(f'Image avec la palette de {num_colors} couleurs (median-cut)')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Mean$ $Square$ $Error$ $(MSE):$ $Erreur$ $Quadratique$ $Moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(image_d_origine, image_traitee):\n",
    "    # Get the dimensions of the images\n",
    "    L, C = np.array(image_d_origine).shape[:2]  # Assuming it's a 2D image, getting rows and columns\n",
    "    image_traitee = np.array(image_traitee).reshape(np.array(image_d_origine).shape)\n",
    "    # Convert the images to NumPy arrays\n",
    "    origine = np.array(image_d_origine)\n",
    "    traitee = np.array(image_traitee)\n",
    "\n",
    "    # Calculate the sum of squared differences\n",
    "    somme_differences_carrees = np.sum((origine - traitee) ** 2)\n",
    "\n",
    "    # Calculate (1 / (L * C)) * somme\n",
    "    resultat = (1 / (L * C)) * somme_differences_carrees\n",
    "\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Taux$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taux_compression(img_path, compressed_file_path):\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    if img.mode == 'RGB':\n",
    "        pixel_size = 3  # Nombre de canaux de couleur (RGB)\n",
    "    else:\n",
    "        pixel_size = 1  # Pour d'autres modes de couleur\n",
    "    \n",
    "    if img.bits == 8:  # Taille en bits par pixel\n",
    "        pixel_bits = 8\n",
    "    else:\n",
    "        pixel_bits = 16  # Peut être ajusté selon les besoins\n",
    "    \n",
    "    img_data_size = img.size[0] * img.size[1] * pixel_size * pixel_bits  # Taille en bits de l'image\n",
    "    \n",
    "    # Lecture des données compressées à partir du fichier .irm\n",
    "    with open(compressed_file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    \n",
    "    compressed_data_size = len(compressed_data) * 8  # Taille des données compressées en bits\n",
    "    \n",
    "    compression_ratio = img_data_size / compressed_data_size  # Ratio de compression\n",
    "    \n",
    "    return compression_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1). $Création$ $de$ $la$ $palette$ $de$ $couleurs$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $allée$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_palette(image, num_colors):\n",
    "    # Convertir l'image en un tableau 2D de pixels\n",
    "    pixels = np.reshape(image, (-1, 3))  # (nombre de pixels, 3 canaux de couleur)\n",
    "\n",
    "    # Appliquer l'algorithme de k-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Obtenir les centres des clusters (couleurs dominantes)\n",
    "    color_palette = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    # Associer chaque pixel à l'indice de couleur dans la palette\n",
    "    labels = kmeans.predict(pixels)\n",
    "\n",
    "    # Reformater les indices des couleurs dans la palette selon la forme de l'image originale\n",
    "    palette_indices = np.reshape(labels, np.array(image).shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Median-cut$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_cut_palette(image, num_colors):\n",
    "    # Convertir l'image en un tableau 2D de pixels\n",
    "    pixels = np.reshape(image, (-1, 3))\n",
    "\n",
    "    # Initialiser la liste des cubes de couleur avec le cube contenant tous les pixels\n",
    "    cubes = [pixels]\n",
    "\n",
    "    # Répéter jusqu'à ce que le nombre de cubes atteigne le nombre de couleurs souhaité\n",
    "    while len(cubes) < num_colors:\n",
    "        # Sélectionner le cube le plus grand\n",
    "        largest_cube_index = np.argmax([cube.shape[0] for cube in cubes])\n",
    "        largest_cube = cubes.pop(largest_cube_index)\n",
    "\n",
    "        # Trouver l'axe dominant pour diviser le cube\n",
    "        axis = np.argmax(np.max(largest_cube, axis=0) - np.min(largest_cube, axis=0))\n",
    "\n",
    "        # Trier les pixels du cube le long de l'axe dominant\n",
    "        sorted_cube = largest_cube[largest_cube[:, axis].argsort()]\n",
    "\n",
    "        # Diviser le cube en deux parties égales\n",
    "        split_index = len(sorted_cube) // 2\n",
    "        cube1 = sorted_cube[:split_index]\n",
    "        cube2 = sorted_cube[split_index:]\n",
    "\n",
    "        # Ajouter les deux nouveaux cubes à la liste\n",
    "        cubes.append(cube1)\n",
    "        cubes.append(cube2)\n",
    "\n",
    "    # Calculer les couleurs moyennes pour chaque cube\n",
    "    color_palette = [np.mean(cube, axis=0) for cube in cubes]\n",
    "    color_palette = np.array(color_palette).astype(np.uint8)\n",
    "\n",
    "    # Calculer les indices des couleurs dans la palette pour chaque pixel de l'image\n",
    "    palette_indices = np.zeros(len(pixels), dtype=int)\n",
    "    for i, pixel in enumerate(pixels):\n",
    "        distances = np.linalg.norm(color_palette - pixel, axis=1)\n",
    "        palette_indices[i] = np.argmin(distances)\n",
    "\n",
    "    palette_indices = np.reshape(palette_indices, np.array(image).shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Octree$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octree_palette(image, num_colors):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "    img_rgb = image.convert(\"RGB\")\n",
    "    img_with_palette = img_rgb.quantize(colors=num_colors, method=Image.FASTOCTREE)\n",
    "    palette = img_with_palette.getpalette()[:num_colors * 3]\n",
    "    palette = np.array(palette).reshape(-1, 3)\n",
    "    indices = np.array(img_with_palette)\n",
    "\n",
    "    # Retourner la palette de couleurs et leurs indices\n",
    "    return palette, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $retour$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_kmeans_clustering_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Median-cut$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_median_cut_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "  \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Octree$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_octree_palette(color_palette, palette_indices):\n",
    "    color_palette = color_palette.reshape(-1)\n",
    "    color_palette = [(int(color_palette[i]), int(color_palette[i + 1]), int(color_palette[i + 2])) for i in range(0, len(color_palette), 3)]\n",
    "    reconstructed_image = Image.new(\"RGB\", (palette_indices.shape[1], palette_indices.shape[0]))\n",
    "    reconstructed_image.putdata([color_palette[idx] for idx in palette_indices.flatten()])\n",
    "  \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2). $Mappage$ $des$ $pixels$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_palette(image, color_palette):\n",
    "    # Assurez-vous que l'image est sous forme de tableau numpy\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # Redimensionner les pixels en une matrice (nombre de pixels, 3 canaux de couleur)\n",
    "    pixels = np.reshape(image, (-1, 3))  \n",
    "\n",
    "    # Calculer la distance de chaque pixel à chaque couleur de la palette\n",
    "    distances = np.linalg.norm(pixels[:, np.newaxis] - color_palette, axis=2)\n",
    "\n",
    "    # Obtenir l'indice de la couleur la plus proche pour chaque pixel\n",
    "    indices = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Reformater les indices des couleurs selon la forme de l'image originale\n",
    "    mapped_indices = np.reshape(indices, image.shape[:2])\n",
    "\n",
    "    return np.array(mapped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_map_to_palette(mapped_indices, color_palette):\n",
    "    # Obtenir les dimensions de l'image reconstruite\n",
    "    height, width = mapped_indices.shape\n",
    "\n",
    "    # Créer une image vide\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Pour chaque pixel, assigner la couleur correspondante de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = mapped_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    return Image.fromarray(reconstructed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3). $Subdivision$ $en$ $blocs$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdivision2D(matrice, taille_blocs):\n",
    "    # Dimensions de la matrice initiale\n",
    "    lignes, colonnes = matrice.shape\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    blocs_lignes, blocs_colonnes = (taille_blocs, taille_blocs)\n",
    "    \n",
    "    # Calcul des dimensions des blocs avec zéros ajoutés\n",
    "    new_blocs_lignes = (lignes + blocs_lignes - 1) // blocs_lignes\n",
    "    new_blocs_colonnes = (colonnes + blocs_colonnes - 1) // blocs_colonnes\n",
    "    \n",
    "    # Initialisation de la matrice des sous-matrices\n",
    "    sous_matrices = np.zeros((new_blocs_lignes, new_blocs_colonnes, blocs_lignes, blocs_colonnes))\n",
    "    \n",
    "    # Remplissage de la matrice des sous-matrices\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            sous_matrices[i, j, :min(blocs_lignes, lignes - i*blocs_lignes), :min(blocs_colonnes, colonnes - j*blocs_colonnes)] = \\\n",
    "                matrice[i*blocs_lignes:(i+1)*blocs_lignes, j*blocs_colonnes:(j+1)*blocs_colonnes]\n",
    "    \n",
    "    # Convertir la matrice de sous-matrices en une liste de matrices 2D\n",
    "    liste_matrices = []\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            liste_matrices.append(sous_matrices[i, j])\n",
    "    \n",
    "    return liste_matrices, (lignes, colonnes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstitution2D(liste_matrices, dimensions):# Récupération des dimensions de la matrice initiale\n",
    "    lignes, colonnes = dimensions\n",
    "    \n",
    "    # Initialisation de la matrice résultante avec des zéros\n",
    "    matrice_resultante = np.zeros((lignes, colonnes))\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    taille_blocs = liste_matrices[0].shape\n",
    "    \n",
    "    # Nombre de blocs\n",
    "    nb_blocs_lignes = (lignes + taille_blocs[0] - 1) // taille_blocs[0]\n",
    "    nb_blocs_colonnes = (colonnes + taille_blocs[1] - 1) // taille_blocs[1]\n",
    "    \n",
    "    # Recombinaison des sous-matrices dans la matrice résultante\n",
    "    for i in range(nb_blocs_lignes):\n",
    "        for j in range(nb_blocs_colonnes):\n",
    "            matrice_resultante[i*taille_blocs[0]:(i+1)*taille_blocs[0], j*taille_blocs[1]:(j+1)*taille_blocs[1]] = \\\n",
    "                liste_matrices[i*nb_blocs_colonnes + j][:min(taille_blocs[0], lignes - i*taille_blocs[0]), :min(taille_blocs[1], colonnes - j*taille_blocs[1])]\n",
    "    \n",
    "    return matrice_resultante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4). $Sous$ $échantillonnage$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_2_0(image):\n",
    "    # Sous-échantillonnage de l'image\n",
    "    sub_image = image[::2, ::2]\n",
    "    \n",
    "    return sub_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_2_2(image):\n",
    "    # Sous-échantillonnage de l'image\n",
    "    sub_image = image[::1, ::2]\n",
    "    \n",
    "    return sub_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_4_4(image):\n",
    "    # La fonction ne fait rien car il n'y a pas de sous-échantillonnage pour le 4:4:4\n",
    "    return image.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_2_0(imSub):\n",
    "    # Répétition des pixels pour restaurer la résolution horizontale\n",
    "    H, W = imSub.shape\n",
    "    res_h = np.repeat(imSub, 2, axis=1)\n",
    "    \n",
    "    # Répétition des pixels pour restaurer la résolution verticale\n",
    "    res_v = np.repeat(res_h, 2, axis=0)\n",
    "    \n",
    "    return res_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_2_2(imSub):\n",
    "    # Répétition des colonnes pour restaurer les canaux de chrominance\n",
    "    res_h = np.repeat(imSub, 2, axis=1)\n",
    "    \n",
    "    return res_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_4_4(imSub):\n",
    "    # L'inverse du sous-échantillonnage 4:4:4 est simplement une copie de l'image d'entrée\n",
    "    return imSub.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5). $Transformée$ $en$ $cosinus$ $discrète:$ $application$ $de$ $la$ $DCT$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dct(matrix):\n",
    "    # Appliquer la DCT à chaque matrice\n",
    "    dct_matrix = dct(dct(matrix.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    return np.array(dct_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dct(dct_matrix):\n",
    "    # Appliquer l'inverse de la DCT à chaque matrice\n",
    "    inverse_dct_matrix = idct(idct(dct_matrix.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    return np.array(inverse_dct_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6). $Quantification$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $minimale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_min(matrix, epsilon=1e-10):\n",
    "    # Déterminer la valeur minimale dans la matrice\n",
    "    min_value = np.min(matrix)\n",
    "    \n",
    "    # Vérifier si la valeur minimale est proche de zéro avant la division\n",
    "    if np.abs(min_value) > epsilon:\n",
    "        # Quantification en utilisant la valeur minimale comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix / min_value)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur minimale est proche de zéro\n",
    "        quantized_dct = np.round(matrix / epsilon)\n",
    "        \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0, 0] = 1\n",
    "    \n",
    "    return quantized_dct, min_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_mean(matrix, epsilon=1e-10):\n",
    "    # Déterminer la valeur minimale et maximale dans la matrice\n",
    "    min_value = np.min(matrix)\n",
    "    max_value = np.max(matrix)\n",
    "    \n",
    "    # Calculer la moyenne des valeurs\n",
    "    mean_value = (max_value + min_value) / 2\n",
    "    \n",
    "    # Vérifier si la valeur moyenne est proche de zéro avant la division\n",
    "    if np.abs(mean_value) > epsilon:\n",
    "        # Quantification en utilisant la valeur moyenne comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix / mean_value)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur moyenne est proche de zéro\n",
    "        quantized_dct = np.round(matrix / epsilon)\n",
    "        \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0, 0] = 1\n",
    "    \n",
    "    return quantized_dct, mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $maximale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_max(matrix, epsilon=1e-10):\n",
    "    # Déterminer la valeur maximale dans la matrice\n",
    "    max_value = np.max(matrix)\n",
    "    \n",
    "    # Vérifier si la valeur maximale est proche de zéro avant la division\n",
    "    if np.abs(max_value) > epsilon:\n",
    "        # Quantification en utilisant la valeur maximale comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix / max_value)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur maximale est proche de zéro\n",
    "        quantized_dct = np.round(matrix / epsilon)\n",
    "        \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0, 0] = 1\n",
    "    \n",
    "    return quantized_dct, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $minimale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_min(quantized_matrix, min_value):\n",
    "    return np.array(quantized_matrix * min_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Vaeur$ $moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_mean(quantized_matrix, mean_value):\n",
    "    return np.array(quantized_matrix * mean_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $maximale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_max(quantized_matrix, max_value):\n",
    "    return np.array(quantized_matrix * max_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7). $Vectorisation$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $ligne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ligne_scan(matrice):\n",
    "  shape = matrice.shape\n",
    "  vecteur = matrice.flatten()\n",
    "  return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $colonne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colonne_scan(matrice):\n",
    "    shape = matrice.shape\n",
    "    vecteur = np.ravel(matrice, order = 'F')\n",
    "    return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $zigzag$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_scan(matrice):\n",
    "  shape = matrice.shape\n",
    "  vecteur = np.concatenate([np.diagonal(matrice[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1 - matrice.shape[0], matrice.shape[0])])\n",
    "  return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $ligne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_ligne_scan(vecteur, shape):\n",
    "  mat = np.array(vecteur).reshape((shape[0], shape[1]))\n",
    "  return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $colonne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_colonne_scan(vecteur, shape):\n",
    "    mat = np.array(vecteur).reshape((shape[0], shape[1]))\n",
    "    return mat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $zigzag$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_zigzag_scan(vector, shape):\n",
    "    rows, cols = shape\n",
    "    mat = np.array([[None] * cols for _ in range(rows)])\n",
    "    row, col = 0, 0\n",
    "    direction = 1\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "        mat[row][col] = vector[i]\n",
    "        if direction == 1:\n",
    "            if col == cols - 1:\n",
    "                row += 1\n",
    "                direction = -1\n",
    "            elif row == 0:\n",
    "                col += 1\n",
    "                direction = -1\n",
    "            else:\n",
    "                row -= 1\n",
    "                col += 1\n",
    "        else:\n",
    "            if row == rows - 1:\n",
    "                col += 1\n",
    "                direction = 1\n",
    "            elif col == 0:\n",
    "                row += 1\n",
    "                direction = 1\n",
    "            else:\n",
    "                row += 1\n",
    "                col -= 1\n",
    "\n",
    "    #return np.array(mat, dtype=np.uint8)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (8). $Codage$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermédiaires$ $(propres$ $à$ $Huffman)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Extraction$ $des$ $caractères$ $et$ $leur$ $fréquence$ $d'apparition$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_chr(chaine):\n",
    "    occ = {c: chaine.count(c) for c in set(chaine)}\n",
    "    return sorted(occ.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Dictionnaire$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_dictionnary_code(node, binString=''):\n",
    "    if isinstance(node, str):\n",
    "        return {node: binString}\n",
    "    (l, r) = node\n",
    "    d = {}\n",
    "    d.update(huffman_dictionnary_code(l, binString + '0'))\n",
    "    d.update(huffman_dictionnary_code(r, binString + '1'))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Arbre$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_tree(chaine):\n",
    "    nodes = ext_chr(chaine)\n",
    "    \n",
    "    while len(nodes) > 1:\n",
    "        (key1, c1) = nodes.pop()\n",
    "        (key2, c2) = nodes.pop()\n",
    "        node = (key1, key2)\n",
    "        nodes.append((node, c1 + c2))\n",
    "        nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return nodes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermédiaires$ $(impropres)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Convertion$ $du$ $type$ $des$ $valeurs$ $du$ $vecteur$ $en$ $entier$ $non$ $signé$ $sur$ $8$ $bits$ $et$ $convertion$ $en$ $une$ $chaine$ $de$ $caractères$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_concatenate(vector):\n",
    "    # Conversion du vecteur en une liste de nombres non signés\n",
    "    unsigned_vector = vector.astype(np.uint8) \n",
    "    \n",
    "    # Obtention de la taille de chaque élément de la liste\n",
    "    element_size = [len(str(i)) for i in unsigned_vector.tolist()]\n",
    "\n",
    "    # Concaténation des nombres non signés en une liste unique\n",
    "    concatenated_list = unsigned_vector.flatten().tolist()\n",
    "    string = ''.join(map(str, concatenated_list))\n",
    "\n",
    "    return string, element_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_convert_and_concatenate(string, element_size):\n",
    "    # Vérification que les arguments sont valides\n",
    "    if not isinstance(string, str) or not isinstance(element_size, list):\n",
    "        raise ValueError(\"Les arguments doivent être une chaîne de caractères et une liste.\")\n",
    "\n",
    "    # Convertir la chaîne en une liste de nombres non signés en utilisant les tailles d'éléments\n",
    "    unsigned_vector = []\n",
    "    start = 0\n",
    "    for size in element_size:\n",
    "        unsigned_vector.append(int(string[start:start+size]))\n",
    "        start += size\n",
    "\n",
    "    # Convertir la liste de nombres non signés en vecteur numpy\n",
    "    vector = np.array(unsigned_vector, dtype=np.int8)\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_huffman(strings):\n",
    "    huffman_tree_result = huffman_tree(strings)  # Stockez l'arbre de Huffman dans une variable distincte\n",
    "    huffmanCode = huffman_dictionnary_code(huffman_tree_result)\n",
    "    compressed_string = ''\n",
    "    \n",
    "    for char in strings:\n",
    "        compressed_string += huffmanCode[char]\n",
    "        \n",
    "    return compressed_string, huffman_tree_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_huffman(compressed_string, huffman_tree):\n",
    "    decoded_string = ''\n",
    "    current_node = huffman_tree\n",
    "    \n",
    "    for bit in compressed_string:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]\n",
    "        else:\n",
    "            current_node = current_node[1]\n",
    "        \n",
    "        if isinstance(current_node, str):\n",
    "            decoded_string += current_node\n",
    "            current_node = huffman_tree\n",
    "    \n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $de$ $codage$ $du$ $vecteur$ $à$ $Huffman$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_concatenated(vect):\n",
    "  string, vect_lengths = convert_and_concatenate(vect)\n",
    "  huffman_code, huffman_tr = encoding_huffman(string)\n",
    "\n",
    "  return huffman_code, huffman_tr, vect_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_deconcatenated(huffman_code, huffman_tr, vect_lengths):\n",
    "    decoded = decoding_huffman(huffman_code, huffman_tr)\n",
    "    vect = inverse_convert_and_concatenate(decoded, vect_lengths)\n",
    "    \n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (9). $Codage$ $par$ $LZW$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermediaires$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Fusion$ $de$ $la$ $liste$ $des$ $codes$ $Huffman$ $de$ $tous$ $les$ $blocs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionner(strings_list):\n",
    "    tailles = []\n",
    "    string_fusionned = \"\"\n",
    "    \n",
    "    # Parcourir tous les éléments de la liste\n",
    "    for string in strings_list:\n",
    "        # Convertir chaque nombre en chaîne de caractères et l'ajouter à la chaîne fusionnée\n",
    "        string_fusionned += string\n",
    "        \n",
    "        # Ajouter la taille de l'élément à la liste des tailles\n",
    "        tailles.append(len(string))\n",
    "    \n",
    "    # Retourner la chaîne de caractères fusionnée et la liste des tailles\n",
    "    return string_fusionned, tailles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Séparation$ $de$ $la$ $liste$ $des$ $codes$ $Huffman$ $de$ $tous$ $les$ $blocs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separer(string_fusionned, tailles):\n",
    "    strings_list = []\n",
    "    debut = 0\n",
    "    \n",
    "    # Parcourir toutes les tailles dans la liste\n",
    "    for taille in tailles:\n",
    "        # Extraire le sous-chaîne correspondant à la taille actuelle\n",
    "        sous_chaine = string_fusionned[debut:debut+taille]\n",
    "        \n",
    "        # Convertir la sous-chaîne en nombre et l'ajouter à la liste des nombres\n",
    "        strings_list.append(sous_chaine)\n",
    "        \n",
    "        # Mettre à jour la position de départ pour la prochaine sous-chaîne\n",
    "        debut += taille\n",
    "    \n",
    "    # Retourner la liste des nombres\n",
    "    return strings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_lzw(data, color_palette):\n",
    "    alphabet = [str(i) for i in range(len(color_palette))]\n",
    "    data_fused, taille = fusionner(data)  # Fusionner les chaînes de caractères\n",
    "    encoded_data = []\n",
    "\n",
    "    dictionary = {}  # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[char] = i\n",
    "\n",
    "    prefix = ''\n",
    "    for char in data_fused:\n",
    "        new_entry = prefix + char\n",
    "        if new_entry in dictionary:\n",
    "            prefix = new_entry\n",
    "        else:\n",
    "            encoded_data.append(dictionary[prefix])\n",
    "            dictionary[new_entry] = len(dictionary)\n",
    "            prefix = char\n",
    "\n",
    "    if prefix:\n",
    "        encoded_data.append(dictionary[prefix])\n",
    "\n",
    "    return encoded_data, alphabet, taille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_lzw(compressed_data, alphabet, tailleL):\n",
    "    result = []\n",
    "    dictionary = {}\n",
    "    current_code = len(alphabet)\n",
    "\n",
    "    # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[i] = char\n",
    "\n",
    "    old_entry = dictionary[compressed_data[0]]\n",
    "    result.append(old_entry)\n",
    "    for new_entry in compressed_data[1:]:\n",
    "        if new_entry in dictionary:\n",
    "            entry = dictionary[new_entry]\n",
    "        elif new_entry == current_code:\n",
    "            entry = old_entry + old_entry[0]\n",
    "        else:\n",
    "            raise ValueError(\"Mauvaise séquence compressée\")\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "        # Utilisez le même dictionnaire pour la décompression\n",
    "        dictionary[current_code] = old_entry + entry[0]\n",
    "        current_code += 1\n",
    "        old_entry = entry\n",
    "\n",
    "    result = ''.join(result)\n",
    "    result = separer(result, tailleL)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaireC(imageA, num_colorsA):\n",
    "  color_paletteA, palette_indicesA = kmeans_clustering_palette(imageA, num_colorsA)\n",
    "  mapped_indicesA = map_to_palette(imageA, color_paletteA)\n",
    "  blocsA, shapeTA = subdivision2D(mapped_indicesA, num_blocs)\n",
    "  dataA = []\n",
    "  huffman_trsA = []\n",
    "  vect_lengthssA = []\n",
    "  \n",
    "  for blocA in blocsA:\n",
    "    result1A = sous_echantillonnage_4_2_0(blocA)\n",
    "    dct_matrixA = apply_dct(result1A)\n",
    "    result11A, mean_valueA = quantization_mean(dct_matrixA)\n",
    "    ligneA, shapetA = ligne_scan(result11A)\n",
    "    huffman_codeA, huffman_trA, vect_lengthsA = huffman_concatenated(ligneA)\n",
    "    \n",
    "    if not huffman_codeA:\n",
    "        print(\"La sortie de la fonction Huffman est vide.\")\n",
    "        print(ligneA)\n",
    "        print(result11A)\n",
    "        \n",
    "    huffman_trsA.append(huffman_trA)\n",
    "    vect_lengthssA.append(vect_lengthsA)\n",
    "    dataA.append(huffman_codeA)\n",
    "  \n",
    "  encoded_dataA, alphabetA, tailleA = encoding_lzw(dataA, color_paletteA)\n",
    "    \n",
    "  return encoded_dataA, alphabetA, tailleA, huffman_trsA, vect_lengthssA, shapeTA, shapetA, mean_valueA, mapped_indicesA, color_paletteA, palette_indicesA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaireD(encoded_dataB, alphabetB, tailleB, huffman_trB, vect_lengthsB, shapeTB, shapetB, mean_valueB, mapped_indicesB, color_paletteB, palette_indicesB):\n",
    "  resultB = decoding_lzw(encoded_dataB, alphabetB, tailleB)\n",
    "  codesB = []\n",
    "\n",
    "  for i in range(len(resultB)):\n",
    "    vect1B = huffman_deconcatenated(resultB[i], huffman_trB[i], vect_lengthsB[i])\n",
    "    matB = inverse_ligne_scan(vect1B, shapetB)\n",
    "    quantB = dequantization_mean(matB, mean_valueB)\n",
    "    dctB = inverse_dct(quantB)\n",
    "    subsapB = inverse_sous_echantillonnage_4_2_0(dctB)\n",
    "    codesB.append(subsapB)\n",
    "  \n",
    "  code7 = reconstitution2D(codesB, shapeTB)\n",
    "  mapp = inverse_map_to_palette(mapped_indicesB, color_paletteB)\n",
    "  imageB = inverse_kmeans_clustering_palette(color_paletteB, palette_indicesB)\n",
    "  return imageB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $création$ $de$ $la$ $partie$ $\"header\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_header(path, num_colors):\n",
    "  image = Image.open(path)\n",
    "  return intermediaireC(image, num_colors)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Création$ $de$ $la$ $partie$ $\"data\"$ $(donnée)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_irm(path, num_colors):\n",
    "  image = Image.open(path)\n",
    "  return intermediaireC(image, num_colors)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Création$ $de$ $la$ $partie$ $\"header\"$ $(entête)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_irm(path, num_colors):\n",
    "    alphabet, taille, huffman_trT, vect_lengthsT, shapeT, shapet, mean_value, mapped_indices, color_palette, palette_indices = create_header(path, num_colors)\n",
    "    header = f\"alphabet: {alphabet}\\n\"\n",
    "    header += f\"taille: {taille}\\n\"\n",
    "    header += f\"huffman_trT: {huffman_trT}\\n\"\n",
    "    header += f\"vect_lengthsT: {vect_lengthsT}\\n\"\n",
    "    header += f\"shapeT: {shapeT}\\n\"\n",
    "    header += f\"shapet: {shapet}\\n\"\n",
    "    header += f\"mean_value: {mean_value}\\n\"\n",
    "    header += f\"mapped_indices: {list(map(list,list(mapped_indices)))}\\n\"\n",
    "    header += f\"color_palette: {list(map(list,list(color_palette)))}\\n\"\n",
    "    header += f\"palette_indices: {list(map(list,list(palette_indices)))}\\n\"\n",
    "    return header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_irm(path1, num_colors, path2):\n",
    "    header = header_irm(path1, num_colors)\n",
    "    data = data_irm(path1, num_colors)\n",
    "    compressed_data = \"\\n\".join(str(nombre) for nombre in data)\n",
    "    with open(path2, 'w') as f:\n",
    "        f.write(header)\n",
    "        f.write(compressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $de$ $décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompression_irm(path1, path2):\n",
    "    with open(path1, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        numeric_lines = [line.strip() for line in lines if re.match(r'^\\d+$', line.strip())]\n",
    "        encoded_data = [int(nombre.strip()) for nombre in numeric_lines]\n",
    "        alphabet = np.array(eval(lines[0].split(': ')[1]))\n",
    "        taille = np.array(eval(lines[1].split(': ')[1]))\n",
    "        huffman_trT = eval(lines[2].split(': ')[1])\n",
    "        vect_lengthsT = eval(lines[3].split(': ')[1])\n",
    "        shapeT = eval(lines[4].split(': ')[1])\n",
    "        shapet = eval(lines[5].split(': ')[1])\n",
    "        mean_value = eval(lines[6].split(': ')[1]) \n",
    "        mapped_indices = np.array(eval(lines[7].split(': ')[1]))\n",
    "        color_palette = np.array(eval(lines[8].split(': ')[1]))\n",
    "        palette_indices = np.array(eval(lines[9].split(': ')[1]))\n",
    "    \n",
    "    image = intermediaireD(encoded_data, alphabet, taille, huffman_trT, vect_lengthsT, shapeT, shapet, mean_value, mapped_indices, color_palette, palette_indices)\n",
    "    image.save(path2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $APPLICATION$ $COMPLÈTE$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/issa-sangare/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompression_irm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_colors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m, in \u001b[0;36mcompression_irm\u001b[0;34m(path1, num_colors, path2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompression_irm\u001b[39m(path1, num_colors, path2):\n\u001b[0;32m----> 2\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[43mheader_irm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_colors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m data_irm(path1, num_colors)\n\u001b[1;32m      4\u001b[0m     compressed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(nombre) \u001b[38;5;28;01mfor\u001b[39;00m nombre \u001b[38;5;129;01min\u001b[39;00m data)\n",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m, in \u001b[0;36mheader_irm\u001b[0;34m(path, num_colors)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mheader_irm\u001b[39m(path, num_colors):\n\u001b[0;32m----> 2\u001b[0m     alphabet, taille, huffman_trT, vect_lengthsT, shapeT, shapet, mean_value, mapped_indices, color_palette, palette_indices \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_colors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     header \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malphabet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphabet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     header \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaille: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtaille\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m, in \u001b[0;36mcreate_header\u001b[0;34m(path, num_colors)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_header\u001b[39m(path, num_colors):\n\u001b[1;32m      2\u001b[0m   image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path)\n\u001b[0;32m----> 3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mintermediaireC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_colors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m, in \u001b[0;36mintermediaireC\u001b[0;34m(imageA, num_colorsA)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintermediaireC\u001b[39m(imageA, num_colorsA):\n\u001b[0;32m----> 2\u001b[0m   color_paletteA, palette_indicesA \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_clustering_palette\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_colorsA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m   mapped_indicesA \u001b[38;5;241m=\u001b[39m map_to_palette(imageA, color_paletteA)\n\u001b[1;32m      4\u001b[0m   blocsA, shapeTA \u001b[38;5;241m=\u001b[39m subdivision2D(mapped_indicesA, num_blocs)\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mkmeans_clustering_palette\u001b[0;34m(image, num_colors)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Appliquer l'algorithme de k-means clustering\u001b[39;00m\n\u001b[1;32m      6\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mnum_colors)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Obtenir les centres des clusters (couleurs dominantes)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m color_palette \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1519\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1515\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1519\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1019\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[init_indices]\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1019\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1027\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[1;32m   1028\u001b[0m         n_samples,\n\u001b[1;32m   1029\u001b[0m         size\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[1;32m   1030\u001b[0m         replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1031\u001b[0m         p\u001b[38;5;241m=\u001b[39msample_weight \u001b[38;5;241m/\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum(),\n\u001b[1;32m   1032\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:255\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    252\u001b[0m np\u001b[38;5;241m.\u001b[39mclip(candidate_ids, \u001b[38;5;28;01mNone\u001b[39;00m, closest_dist_sq\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, out\u001b[38;5;241m=\u001b[39mcandidate_ids)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Compute distances to center candidates\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m distance_to_candidates \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# update closest distances squared and potential for each candidate\u001b[39;00m\n\u001b[1;32m    260\u001b[0m np\u001b[38;5;241m.\u001b[39mminimum(closest_dist_sq, distance_to_candidates, out\u001b[38;5;241m=\u001b[39mdistance_to_candidates)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:382\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    380\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n\u001b[0;32m--> 382\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compression_irm(path, num_colors, path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = data_irm(path, num_colors)\n",
    "result = header_irm(path, num_colors)\n",
    "img = intermediaireD(result1, result[0], result[1], result[2], result[3], result[4], result[5], result[6], result[7], result[8], result[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[197], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecompression_irm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[195], line 17\u001b[0m, in \u001b[0;36mdecompression_irm\u001b[0;34m(path1, path2)\u001b[0m\n\u001b[1;32m     14\u001b[0m     color_palette \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28meval\u001b[39m(lines[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     15\u001b[0m     palette_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28meval\u001b[39m(lines[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 17\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mintermediaireD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtaille\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuffman_trT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvect_lengthsT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapeT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_palette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m image\u001b[38;5;241m.\u001b[39msave(path2)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "Cell \u001b[0;32mIn[190], line 6\u001b[0m, in \u001b[0;36mintermediaireD\u001b[0;34m(encoded_dataB, alphabetB, tailleB, huffman_trB, vect_lengthsB, shapeTB, shapetB, mean_valueB, mapped_indicesB, color_paletteB, palette_indicesB)\u001b[0m\n\u001b[1;32m      3\u001b[0m codesB \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(resultB)):\n\u001b[0;32m----> 6\u001b[0m   vect1B \u001b[38;5;241m=\u001b[39m \u001b[43mhuffman_deconcatenated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresultB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuffman_trB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvect_lengthsB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m   matB \u001b[38;5;241m=\u001b[39m inverse_ligne_scan(vect1B, shapetB)\n\u001b[1;32m      8\u001b[0m   quantB \u001b[38;5;241m=\u001b[39m dequantization_mean(matB, mean_valueB)\n",
      "Cell \u001b[0;32mIn[184], line 3\u001b[0m, in \u001b[0;36mhuffman_deconcatenated\u001b[0;34m(huffman_code, huffman_tr, vect_lengths)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhuffman_deconcatenated\u001b[39m(huffman_code, huffman_tr, vect_lengths):\n\u001b[1;32m      2\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m decoding_huffman(huffman_code, huffman_tr)\n\u001b[0;32m----> 3\u001b[0m     vect \u001b[38;5;241m=\u001b[39m \u001b[43minverse_convert_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvect_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vect\n",
      "Cell \u001b[0;32mIn[180], line 10\u001b[0m, in \u001b[0;36minverse_convert_and_concatenate\u001b[0;34m(string, element_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m element_size:\n\u001b[0;32m---> 10\u001b[0m     unsigned_vector\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     start \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convertir la liste de nombres non signés en vecteur numpy\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "decompression_irm(path1, path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Affichage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open(path)\n",
    "img2 = Image.open(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_images\u001b[49m(img1, img2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_images' is not defined"
     ]
    }
   ],
   "source": [
    "plot_images(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Mean$ $Square$ $Error$ $(MSE):$ $Erreur$ $Quadratique$ $Moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur = MSE(img1, img2)\n",
    "print(f\"L'erreur quadratique moyenne (MSE) est: {erreur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Taux$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taux = taux_compression(path, path2)\n",
    "print(f\"Taux de compression: {100 * taux} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
