{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Importation$ $des$ $bibliothèques$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.fftpack import dct, idct\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import heapq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Données/Informations$ $utilisées$ $pour$ $le$ $programme$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'eren_rgb.jpg'\n",
    "path1 = 'file.txt'\n",
    "path2 = 'reconstiued3.jpg'\n",
    "num_rows = 4\n",
    "num_colors = 16\n",
    "num_blocs = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Caratéristiques$ $de$ $l'image$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def details(path):\n",
    "    img = Image.open(path)\n",
    "    size = img.size\n",
    "    format = img.format\n",
    "    mode = img.mode\n",
    "    resolution = img.info.get('dpi')\n",
    "    definition = size[0] * size[1]\n",
    "    definition2 = size\n",
    "    \n",
    "    if resolution is not None:\n",
    "        size = (size[0]/ resolution[0], size[1] / resolution[1])\n",
    "    else:\n",
    "        size = (0, 0)  # or any default resolution you want to use\n",
    "    \n",
    "    poids = os.path.getsize(path) / (1000.0)  # Convert to kilobytes\n",
    "    \n",
    "    if mode == 'RGB':\n",
    "        trsc = definition * 3 * img.bits\n",
    "    else:\n",
    "        trsc = definition * 1 * img.bits\n",
    "    \n",
    "    trsc /= (1024 * 8)\n",
    "    \n",
    "    taux_compression = 100 * (1 - (poids/trsc))\n",
    "        \n",
    "    return size, format, mode, resolution, definition, definition2, poids, trsc, taux_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (inch): (0, 0)\n",
      "Format: JPEG\n",
      "Mode: RGB\n",
      "Resolution: None\n",
      "Definition (pixels): 49728\n",
      "Définition (L * C): (224, 222)\n",
      "Taille en mémoire avec compression: 12.665 KB\n",
      "Taille réelle sans compression: 0.14227294921875 MB\n",
      "Taux de compression:  91.3067353067353 %\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "result = details(path)\n",
    "print(\"Size (inch):\", result[0])\n",
    "print(\"Format:\", result[1])\n",
    "print(\"Mode:\", result[2])\n",
    "print(\"Resolution:\", result[3])\n",
    "print(\"Definition (pixels):\", result[4])\n",
    "print(\"Définition (L * C):\", result[5])\n",
    "print(\"Taille en mémoire avec compression:\", result[6], \"KB\")\n",
    "print(\"Taille réelle sans compression:\", result[7]/1024, \"MB\")\n",
    "print(\"Taux de compression: \", result[8], \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Affichage$ $de$ $la$ $palette$ $de$ $couleurs$ $et$ $des$ $images$ $avant$ $et$ $après$ $application$ $de$ $la$ $palette$ $de$ $couleurs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_palette(image, color_palette, palette_indices, num_rows):\n",
    "    num_colors = len(color_palette)\n",
    "    num_cols = num_colors // num_rows\n",
    "\n",
    "    image_with_palette = color_palette[palette_indices]\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    for i, color in enumerate(color_palette):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        color_patch = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        color_patch[:, :] = color\n",
    "        plt.imshow(color_patch)\n",
    "        plt.title(f'Couleur {i+1}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Palette de couleurs', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))\n",
    "    fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Image originale')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(image_with_palette)\n",
    "    axs[1].set_title(f'Image avec la palette de {num_colors} couleurs')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Affichage$ $de$ $deux$ $images$ $quelconques$ $côte$ $à$ $côte$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(reconstructed_image, image1, num_colors):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 15))\n",
    "    fig.subplots_adjust(wspace=0.01)\n",
    "\n",
    "    axs[0].imshow(reconstructed_image)\n",
    "    axs[0].set_title('Image reconstruite')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(image1)\n",
    "    axs[1].set_title(f'Image avec la palette de {num_colors} couleurs (median-cut)')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Mean$ $Square$ $Error$ $(MSE):$ $Erreur$ $Quadratique$ $Moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(image_d_origine, image_traitee):\n",
    "    # Get the dimensions of the images\n",
    "    L, C = np.array(image_d_origine).shape[:2]  # Assuming it's a 2D image, getting rows and columns\n",
    "    image_traitee = np.array(image_traitee).reshape(np.array(image_d_origine).shape)\n",
    "    # Convert the images to NumPy arrays\n",
    "    origine = np.array(image_d_origine)\n",
    "    traitee = np.array(image_traitee)\n",
    "\n",
    "    # Calculate the sum of squared differences\n",
    "    somme_differences_carrees = np.sum((origine - traitee) ** 2)\n",
    "\n",
    "    # Calculate (1 / (L * C)) * somme\n",
    "    resultat = (1 / (L * C)) * somme_differences_carrees\n",
    "\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $Taux$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taux_compression(img_path, compressed_file_path):\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    if img.mode == 'RGB':\n",
    "        pixel_size = 3  # Nombre de canaux de couleur (RGB)\n",
    "    else:\n",
    "        pixel_size = 1  # Pour d'autres modes de couleur\n",
    "    \n",
    "    if img.bits == 8:  # Taille en bits par pixel\n",
    "        pixel_bits = 8\n",
    "    else:\n",
    "        pixel_bits = 16  # Peut être ajusté selon les besoins\n",
    "    \n",
    "    img_data_size = img.size[0] * img.size[1] * pixel_size * pixel_bits  # Taille en bits de l'image\n",
    "    \n",
    "    # Lecture des données compressées à partir du fichier .irm\n",
    "    with open(compressed_file_path, 'rb') as f:\n",
    "        compressed_data = f.read()\n",
    "    \n",
    "    compressed_data_size = len(compressed_data) * 8  # Taille des données compressées en bits\n",
    "    \n",
    "    compression_ratio = img_data_size / compressed_data_size  # Ratio de compression\n",
    "    \n",
    "    return compression_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1). $Création$ $de$ $la$ $palette$ $de$ $couleurs$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $allée$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_palette(image, num_colors):\n",
    "    # Convertir l'image en un tableau 2D de pixels\n",
    "    pixels = np.reshape(image, (-1, 3))  # (nombre de pixels, 3 canaux de couleur)\n",
    "\n",
    "    # Appliquer l'algorithme de k-means clustering\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "\n",
    "    # Obtenir les centres des clusters (couleurs dominantes)\n",
    "    color_palette = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    # Associer chaque pixel à l'indice de couleur dans la palette\n",
    "    labels = kmeans.predict(pixels)\n",
    "\n",
    "    # Reformater les indices des couleurs dans la palette selon la forme de l'image originale\n",
    "    palette_indices = np.reshape(labels, np.array(image).shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Median-cut$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_cut_palette(image, num_colors):\n",
    "    # Convertir l'image en un tableau 2D de pixels\n",
    "    pixels = np.reshape(image, (-1, 3))\n",
    "\n",
    "    # Initialiser la liste des cubes de couleur avec le cube contenant tous les pixels\n",
    "    cubes = [pixels]\n",
    "\n",
    "    # Répéter jusqu'à ce que le nombre de cubes atteigne le nombre de couleurs souhaité\n",
    "    while len(cubes) < num_colors:\n",
    "        # Sélectionner le cube le plus grand\n",
    "        largest_cube_index = np.argmax([cube.shape[0] for cube in cubes])\n",
    "        largest_cube = cubes.pop(largest_cube_index)\n",
    "\n",
    "        # Trouver l'axe dominant pour diviser le cube\n",
    "        axis = np.argmax(np.max(largest_cube, axis=0) - np.min(largest_cube, axis=0))\n",
    "\n",
    "        # Trier les pixels du cube le long de l'axe dominant\n",
    "        sorted_cube = largest_cube[largest_cube[:, axis].argsort()]\n",
    "\n",
    "        # Diviser le cube en deux parties égales\n",
    "        split_index = len(sorted_cube) // 2\n",
    "        cube1 = sorted_cube[:split_index]\n",
    "        cube2 = sorted_cube[split_index:]\n",
    "\n",
    "        # Ajouter les deux nouveaux cubes à la liste\n",
    "        cubes.append(cube1)\n",
    "        cubes.append(cube2)\n",
    "\n",
    "    # Calculer les couleurs moyennes pour chaque cube\n",
    "    color_palette = [np.mean(cube, axis=0) for cube in cubes]\n",
    "    color_palette = np.array(color_palette).astype(np.uint8)\n",
    "\n",
    "    # Calculer les indices des couleurs dans la palette pour chaque pixel de l'image\n",
    "    palette_indices = np.zeros(len(pixels), dtype=int)\n",
    "    for i, pixel in enumerate(pixels):\n",
    "        distances = np.linalg.norm(color_palette - pixel, axis=1)\n",
    "        palette_indices[i] = np.argmin(distances)\n",
    "\n",
    "    palette_indices = np.reshape(palette_indices, np.array(image).shape[:2])\n",
    "\n",
    "    return color_palette, palette_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Octree$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def octree_palette(image, num_colors):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "    img_rgb = image.convert(\"RGB\")\n",
    "    img_with_palette = img_rgb.quantize(colors=num_colors, method=Image.FASTOCTREE)\n",
    "    palette = img_with_palette.getpalette()[:num_colors * 3]\n",
    "    palette = np.array(palette).reshape(-1, 3)\n",
    "    indices = np.array(img_with_palette)\n",
    "\n",
    "    # Retourner la palette de couleurs et leurs indices\n",
    "    return palette, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $retour$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k-means$ $clustering$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_kmeans_clustering_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Median-cut$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_median_cut_palette(color_palette, palette_indices):\n",
    "    # Récupérer les dimensions de l'image à partir des indices de palette\n",
    "    height, width = palette_indices.shape\n",
    "\n",
    "    # Initialiser une image vide avec les dimensions récupérées\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Remplir l'image reconstruite avec les couleurs de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = palette_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "  \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Octree$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_octree_palette(color_palette, palette_indices):\n",
    "    color_palette = color_palette.reshape(-1)\n",
    "    color_palette = [(int(color_palette[i]), int(color_palette[i + 1]), int(color_palette[i + 2])) for i in range(0, len(color_palette), 3)]\n",
    "    reconstructed_image = Image.new(\"RGB\", (palette_indices.shape[1], palette_indices.shape[0]))\n",
    "    reconstructed_image.putdata([color_palette[idx] for idx in palette_indices.flatten()])\n",
    "  \n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2). $Mappage$ $des$ $pixels$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_palette(image, color_palette):\n",
    "    # Assurez-vous que l'image est sous forme de tableau numpy\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # Redimensionner les pixels en une matrice (nombre de pixels, 3 canaux de couleur)\n",
    "    pixels = np.reshape(image, (-1, 3))  \n",
    "\n",
    "    # Calculer la distance de chaque pixel à chaque couleur de la palette\n",
    "    distances = np.linalg.norm(pixels[:, np.newaxis] - color_palette, axis=2)\n",
    "\n",
    "    # Obtenir l'indice de la couleur la plus proche pour chaque pixel\n",
    "    indices = np.argmin(distances, axis=1)\n",
    "\n",
    "    # Reformater les indices des couleurs selon la forme de l'image originale\n",
    "    mapped_indices = np.reshape(indices, image.shape[:2])\n",
    "\n",
    "    return np.array(mapped_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_map_to_palette(mapped_indices, color_palette):\n",
    "    # Obtenir les dimensions de l'image reconstruite\n",
    "    height, width = mapped_indices.shape\n",
    "\n",
    "    # Créer une image vide\n",
    "    reconstructed_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Pour chaque pixel, assigner la couleur correspondante de la palette\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            color_index = mapped_indices[i, j]\n",
    "            reconstructed_image[i, j] = color_palette[color_index]\n",
    "\n",
    "    return Image.fromarray(reconstructed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3). $Subdivision$ $en$ $blocs$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdivision2D(matrice, taille_blocs):\n",
    "    # Dimensions de la matrice initiale\n",
    "    lignes, colonnes = matrice.shape\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    blocs_lignes, blocs_colonnes = (taille_blocs, taille_blocs)\n",
    "    \n",
    "    # Calcul des dimensions des blocs avec zéros ajoutés\n",
    "    new_blocs_lignes = (lignes + blocs_lignes - 1) // blocs_lignes\n",
    "    new_blocs_colonnes = (colonnes + blocs_colonnes - 1) // blocs_colonnes\n",
    "    \n",
    "    # Initialisation de la matrice des sous-matrices\n",
    "    sous_matrices = np.zeros((new_blocs_lignes, new_blocs_colonnes, blocs_lignes, blocs_colonnes))\n",
    "    \n",
    "    # Remplissage de la matrice des sous-matrices\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            sous_matrices[i, j, :min(blocs_lignes, lignes - i*blocs_lignes), :min(blocs_colonnes, colonnes - j*blocs_colonnes)] = \\\n",
    "                matrice[i*blocs_lignes:(i+1)*blocs_lignes, j*blocs_colonnes:(j+1)*blocs_colonnes]\n",
    "    \n",
    "    # Convertir la matrice de sous-matrices en une liste de matrices 2D\n",
    "    liste_matrices = []\n",
    "    for i in range(new_blocs_lignes):\n",
    "        for j in range(new_blocs_colonnes):\n",
    "            liste_matrices.append(sous_matrices[i, j])\n",
    "    \n",
    "    return liste_matrices, (lignes, colonnes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstitution2D(liste_matrices, dimensions):# Récupération des dimensions de la matrice initiale\n",
    "    lignes, colonnes = dimensions\n",
    "    \n",
    "    # Initialisation de la matrice résultante avec des zéros\n",
    "    matrice_resultante = np.zeros((lignes, colonnes))\n",
    "    \n",
    "    # Dimensions des blocs\n",
    "    taille_blocs = liste_matrices[0].shape\n",
    "    \n",
    "    # Nombre de blocs\n",
    "    nb_blocs_lignes = (lignes + taille_blocs[0] - 1) // taille_blocs[0]\n",
    "    nb_blocs_colonnes = (colonnes + taille_blocs[1] - 1) // taille_blocs[1]\n",
    "    \n",
    "    # Recombinaison des sous-matrices dans la matrice résultante\n",
    "    for i in range(nb_blocs_lignes):\n",
    "        for j in range(nb_blocs_colonnes):\n",
    "            matrice_resultante[i*taille_blocs[0]:(i+1)*taille_blocs[0], j*taille_blocs[1]:(j+1)*taille_blocs[1]] = \\\n",
    "                liste_matrices[i*nb_blocs_colonnes + j][:min(taille_blocs[0], lignes - i*taille_blocs[0]), :min(taille_blocs[1], colonnes - j*taille_blocs[1])]\n",
    "    \n",
    "    return matrice_resultante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4). $Sous$ $échantillonnage$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_2_0(image):\n",
    "    # Sous-échantillonnage de l'image\n",
    "    sub_image = image[::2, ::2]\n",
    "    \n",
    "    return sub_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_2_2(image):\n",
    "    # Sous-échantillonnage de l'image\n",
    "    sub_image = image[::1, ::2]\n",
    "    \n",
    "    return sub_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sous_echantillonnage_4_4_4(image):\n",
    "    # La fonction ne fait rien car il n'y a pas de sous-échantillonnage pour le 4:4:4\n",
    "    return image.copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_2_0(imSub):\n",
    "    # Répétition des pixels pour restaurer la résolution horizontale\n",
    "    H, W = imSub.shape\n",
    "    res_h = np.repeat(imSub, 2, axis=1)\n",
    "    \n",
    "    # Répétition des pixels pour restaurer la résolution verticale\n",
    "    res_v = np.repeat(res_h, 2, axis=0)\n",
    "    \n",
    "    return res_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:2:2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_2_2(imSub):\n",
    "    # Répétition des colonnes pour restaurer les canaux de chrominance\n",
    "    res_h = np.repeat(imSub, 2, axis=1)\n",
    "    \n",
    "    return res_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $4:4:4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_sous_echantillonnage_4_4_4(imSub):\n",
    "    # L'inverse du sous-échantillonnage 4:4:4 est simplement une copie de l'image d'entrée\n",
    "    return imSub.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5). $Transformée$ $en$ $cosinus$ $discrète:$ $application$ $de$ $la$ $DCT$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dct(matrix):\n",
    "    # Appliquer la DCT à chaque matrice\n",
    "    dct_matrix = dct(dct(matrix.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    return np.array(dct_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_dct(dct_matrix):\n",
    "    # Appliquer l'inverse de la DCT à chaque matrice\n",
    "    inverse_dct_matrix = idct(idct(dct_matrix.T, norm='ortho').T, norm='ortho')\n",
    "    \n",
    "    return np.array(inverse_dct_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6). $Quantification$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $minimale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_min(matrix):\n",
    "    # Déterminer la valeur minimale dans la matrice\n",
    "    min_value = np.min(matrix)\n",
    "    \n",
    "    # Vérifier si la valeur minimale est proche de zéro avant la division\n",
    "    if np.abs(min_value) == 0:\n",
    "        min_value = 1\n",
    "        # Quantification en utilisant la valeur minimale comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur minimale est proche de zéro\n",
    "        quantized_dct = np.round(matrix / min_value)\n",
    "    \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0][0] = 1\n",
    "    \n",
    "    return quantized_dct, min_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_mean(matrix):\n",
    "    # Déterminer la valeur minimale et maximale dans la matrice\n",
    "    min_value = np.min(matrix)\n",
    "    max_value = np.max(matrix)\n",
    "    \n",
    "    # Calculer la moyenne des valeurs\n",
    "    mean_value = (max_value + min_value) / 2\n",
    "    \n",
    "    # Vérifier si la valeur moyenne est proche de zéro avant la division\n",
    "    if np.abs(mean_value) == 0:\n",
    "        mean_value = 1\n",
    "        # Quantification en utilisant la valeur moyenne comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur moyenne est proche de zéro\n",
    "        quantized_dct = np.round(matrix / mean_value)\n",
    "    \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0][0] = 1\n",
    "    \n",
    "    return quantized_dct, mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $maximale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization_max(matrix):\n",
    "    # Déterminer la valeur maximale dans la matrice\n",
    "    max_value = np.max(matrix)\n",
    "    \n",
    "    # Vérifier si la valeur maximale est proche de zéro avant la division\n",
    "    if np.abs(max_value) == 0:\n",
    "        max_value = 1\n",
    "        # Quantification en utilisant la valeur maximale comme facteur de quantification\n",
    "        quantized_dct = np.round(matrix)\n",
    "    else:\n",
    "        # Division par epsilon si la valeur maximale est proche de zéro\n",
    "        quantized_dct = np.round(matrix / max_value)\n",
    "    \n",
    "    if np.all(quantized_dct == 0):\n",
    "        quantized_dct[0][0] = 1\n",
    "    \n",
    "    return quantized_dct, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $minimale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_min(quantized_matrix, min_value):\n",
    "    return np.array(quantized_matrix * min_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Vaeur$ $moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_mean(quantized_matrix, mean_value):\n",
    "    return np.array(quantized_matrix * mean_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Valeur$ $maximale$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantization_max(quantized_matrix, max_value):\n",
    "    return np.array(quantized_matrix * max_value, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7). $Vectorisation$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $ligne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ligne_scan(matrice):\n",
    "  shape = matrice.shape\n",
    "  vecteur = matrice.flatten()\n",
    "  return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $colonne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colonne_scan(matrice):\n",
    "    shape = matrice.shape\n",
    "    vecteur = np.ravel(matrice, order = 'F')\n",
    "    return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $zigzag$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zigzag_scan(matrice):\n",
    "  shape = matrice.shape\n",
    "  vecteur = np.concatenate([np.diagonal(matrice[::-1,:], i)[::(2*(i % 2)-1)] for i in range(1 - matrice.shape[0], matrice.shape[0])])\n",
    "  return np.array(vecteur, dtype=np.int8), shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $ligne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_ligne_scan(vecteur, shape):\n",
    "  mat = np.array(vecteur).reshape((shape[0], shape[1]))\n",
    "  return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $colonne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_colonne_scan(vecteur, shape):\n",
    "    mat = np.array(vecteur).reshape((shape[0], shape[1]))\n",
    "    return mat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $En$ $zigzag$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_zigzag_scan(vector, shape):\n",
    "    rows, cols = shape\n",
    "    mat = np.array([[None] * cols for _ in range(rows)])\n",
    "    row, col = 0, 0\n",
    "    direction = 1\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "        mat[row][col] = vector[i]\n",
    "        if direction == 1:\n",
    "            if col == cols - 1:\n",
    "                row += 1\n",
    "                direction = -1\n",
    "            elif row == 0:\n",
    "                col += 1\n",
    "                direction = -1\n",
    "            else:\n",
    "                row -= 1\n",
    "                col += 1\n",
    "        else:\n",
    "            if row == rows - 1:\n",
    "                col += 1\n",
    "                direction = 1\n",
    "            elif col == 0:\n",
    "                row += 1\n",
    "                direction = 1\n",
    "            else:\n",
    "                row += 1\n",
    "                col -= 1\n",
    "\n",
    "    #return np.array(mat, dtype=np.uint8)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (8). $Codage$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermédiaires$ $(propres$ $à$ $Huffman)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Extraction$ $des$ $caractères$ $et$ $leur$ $fréquence$ $d'apparition$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_chr(chaine):\n",
    "    occ = {c: chaine.count(c) for c in set(chaine)}\n",
    "    return sorted(occ.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Dictionnaire$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_dictionnary_code(node, binString=''):\n",
    "    if isinstance(node, str):\n",
    "        return {node: binString}\n",
    "    (l, r) = node\n",
    "    d = {}\n",
    "    d.update(huffman_dictionnary_code(l, binString + '0'))\n",
    "    d.update(huffman_dictionnary_code(r, binString + '1'))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Arbre$ $de$ $Huffman$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_tree(chaine):\n",
    "    nodes = ext_chr(chaine)\n",
    "    \n",
    "    while len(nodes) > 1:\n",
    "        (key1, c1) = nodes.pop()\n",
    "        (key2, c2) = nodes.pop()\n",
    "        node = (key1, key2)\n",
    "        nodes.append((node, c1 + c2))\n",
    "        nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return nodes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermédiaires$ $(impropres)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Convertion$ $du$ $type$ $des$ $valeurs$ $du$ $vecteur$ $en$ $entier$ $non$ $signé$ $sur$ $8$ $bits$ $et$ $convertion$ $en$ $une$ $chaine$ $de$ $caractères$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a). $Sens$ $\"allée\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(data):\n",
    "    encoded_data = \"\"\n",
    "    current_char = data[0]\n",
    "    count = 1\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] == current_char:\n",
    "            count += 1\n",
    "        else:\n",
    "            if count > 1:  # Ajout de cette condition\n",
    "                encoded_data += str(current_char) + \"_\" + str(count) + \"*\"\n",
    "            else:\n",
    "                encoded_data += str(current_char) + \"*\"\n",
    "            current_char = data[i]\n",
    "            count = 1\n",
    "\n",
    "    if count > 1:  # Ajout de cette condition\n",
    "        encoded_data += str(current_char) + \"_\" + str(count)\n",
    "    else:\n",
    "        encoded_data += str(current_char)\n",
    "\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(encoded_data):\n",
    "    decoded_data = []\n",
    "    encoded_data_split = encoded_data.split('*')\n",
    "\n",
    "    for item in encoded_data_split:\n",
    "        if \"_\" in item:\n",
    "            char, count = item.split(\"_\")\n",
    "            char = float(char)\n",
    "            if char.is_integer():\n",
    "                char = int(char)\n",
    "            decoded_data.extend([char] * int(count))\n",
    "        else:\n",
    "            char = float(item)\n",
    "            if char.is_integer():\n",
    "                char = int(char)\n",
    "            decoded_data.append(char)\n",
    "\n",
    "    return decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_concatenate(vector):\n",
    "    # Conversion du vecteur en une liste de nombres non signés\n",
    "    unsigned_vector = vector.astype(np.uint8) \n",
    "    \n",
    "    # Obtention de la taille de chaque élément de la liste\n",
    "    element_size = [len(str(i)) for i in unsigned_vector.tolist()]\n",
    "\n",
    "    # Concaténation des nombres non signés en une liste unique\n",
    "    concatenated_list = unsigned_vector.flatten().tolist()\n",
    "    string = ''.join(map(str, concatenated_list))\n",
    "\n",
    "    return string, element_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b). $Sens$ $\"retour\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_convert_and_concatenate(string, element_size):\n",
    "    # Vérification que les arguments sont valides\n",
    "    if not isinstance(string, str) or not isinstance(element_size, list):\n",
    "        raise ValueError(\"Les arguments doivent être une chaîne de caractères et une liste.\")\n",
    "\n",
    "    # Convertir la chaîne en une liste de nombres non signés en utilisant les tailles d'éléments\n",
    "    unsigned_vector = []\n",
    "    start = 0\n",
    "    for size in element_size:\n",
    "        unsigned_vector.append(int(string[start:start+size]))\n",
    "        start += size\n",
    "\n",
    "    # Convertir la liste de nombres non signés en vecteur numpy\n",
    "    vector = np.array(unsigned_vector, dtype=np.int8)\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_huffman(strings):\n",
    "    huffman_tree_result = huffman_tree(strings)  # Stockez l'arbre de Huffman dans une variable distincte\n",
    "    huffmanCode = huffman_dictionnary_code(huffman_tree_result)\n",
    "    compressed_string = ''\n",
    "    \n",
    "    for char in strings:\n",
    "        compressed_string += huffmanCode[char]\n",
    "        \n",
    "    return compressed_string, huffman_tree_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_huffman(compressed_string, huffman_tree):\n",
    "    decoded_string = ''\n",
    "    current_node = huffman_tree\n",
    "    \n",
    "    for bit in compressed_string:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]\n",
    "        else:\n",
    "            current_node = current_node[1]\n",
    "        \n",
    "        if isinstance(current_node, str):\n",
    "            decoded_string += current_node\n",
    "            current_node = huffman_tree\n",
    "    \n",
    "    return decoded_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $de$ $codage$ $du$ $vecteur$ $à$ $Huffman$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_concatenated(vect):\n",
    "  string, vect_lengths = convert_and_concatenate(vect)\n",
    "  huffman_code, huffman_tr = encoding_huffman(string)\n",
    "\n",
    "  return huffman_code, huffman_tr, vect_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_deconcatenated(huffman_code, huffman_tr, vect_lengths):\n",
    "    decoded = decoding_huffman(huffman_code, huffman_tr)\n",
    "    vect = inverse_convert_and_concatenate(decoded, vect_lengths)\n",
    "    \n",
    "    return vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (9). $Codage$ $par$ $LZW$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (-). $Fonctions$ $intermediaires$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Fusion$ $de$ $la$ $liste$ $des$ $codes$ $Huffman$ $de$ $tous$ $les$ $blocs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionner(strings_list):\n",
    "    tailles = []\n",
    "    string_fusionned = \"\"\n",
    "    \n",
    "    # Parcourir tous les éléments de la liste\n",
    "    for string in strings_list:\n",
    "        # Convertir chaque nombre en chaîne de caractères et l'ajouter à la chaîne fusionnée\n",
    "        string_fusionned += string\n",
    "        \n",
    "        # Ajouter la taille de l'élément à la liste des tailles\n",
    "        tailles.append(len(string))\n",
    "    \n",
    "    # Retourner la chaîne de caractères fusionnée et la liste des tailles\n",
    "    return string_fusionned, tailles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Séparation$ $de$ $la$ $liste$ $des$ $codes$ $Huffman$ $de$ $tous$ $les$ $blocs$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separer(string_fusionned, tailles):\n",
    "    strings_list = []\n",
    "    debut = 0\n",
    "    \n",
    "    # Parcourir toutes les tailles dans la liste\n",
    "    for taille in tailles:\n",
    "        # Extraire le sous-chaîne correspondant à la taille actuelle\n",
    "        sous_chaine = string_fusionned[debut:debut+taille]\n",
    "        \n",
    "        # Convertir la sous-chaîne en nombre et l'ajouter à la liste des nombres\n",
    "        strings_list.append(sous_chaine)\n",
    "        \n",
    "        # Mettre à jour la position de départ pour la prochaine sous-chaîne\n",
    "        debut += taille\n",
    "    \n",
    "    # Retourner la liste des nombres\n",
    "    return strings_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a). $Codage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_lzw(data, color_palette):\n",
    "    alphabet = [str(i) for i in range(len(color_palette))]\n",
    "    data_fused, taille = fusionner(data)  # Fusionner les chaînes de caractères\n",
    "    encoded_data = []\n",
    "\n",
    "    dictionary = {}  # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[char] = i\n",
    "\n",
    "    prefix = ''\n",
    "    for char in data_fused:\n",
    "        new_entry = prefix + char\n",
    "        if new_entry in dictionary:\n",
    "            prefix = new_entry\n",
    "        else:\n",
    "            encoded_data.append(dictionary[prefix])\n",
    "            dictionary[new_entry] = len(dictionary)\n",
    "            prefix = char\n",
    "\n",
    "    if prefix:\n",
    "        encoded_data.append(dictionary[prefix])\n",
    "\n",
    "    return encoded_data, alphabet, taille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b). $Décodage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_lzw(compressed_data, alphabet, tailleL):\n",
    "    result = []\n",
    "    dictionary = {}\n",
    "    current_code = len(alphabet)\n",
    "\n",
    "    # Initialiser le dictionnaire avec les caractères de l'alphabet spécifié\n",
    "    for i, char in enumerate(alphabet):\n",
    "        dictionary[i] = char\n",
    "\n",
    "    old_entry = dictionary[compressed_data[0]]\n",
    "    result.append(old_entry)\n",
    "    for new_entry in compressed_data[1:]:\n",
    "        if new_entry in dictionary:\n",
    "            entry = dictionary[new_entry]\n",
    "        elif new_entry == current_code:\n",
    "            entry = old_entry + old_entry[0]\n",
    "        else:\n",
    "            raise ValueError(\"Mauvaise séquence compressée\")\n",
    "\n",
    "        result.append(entry)\n",
    "\n",
    "        # Utilisez le même dictionnaire pour la décompression\n",
    "        dictionary[current_code] = old_entry + entry[0]\n",
    "        current_code += 1\n",
    "        old_entry = entry\n",
    "\n",
    "    result = ''.join(result)\n",
    "    result = separer(result, tailleL)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaireC(imageA, num_colorsA):\n",
    "  color_paletteA, palette_indicesA = kmeans_clustering_palette(imageA, num_colorsA)\n",
    "  mapped_indicesA = map_to_palette(imageA, color_paletteA)\n",
    "  blocsA, shapeTA = subdivision2D(mapped_indicesA, num_blocs)\n",
    "  dataA = []\n",
    "  huffman_trsA = []\n",
    "  vect_lengthssA = []\n",
    "  \n",
    "  for blocA in blocsA:\n",
    "    result1A = sous_echantillonnage_4_2_0(blocA)\n",
    "    dct_matrixA = apply_dct(result1A)\n",
    "    result11A, mean_valueA = quantization_mean(dct_matrixA)\n",
    "    ligneA, shapetA = ligne_scan(result11A)\n",
    "    rleA = rle_encode(ligneA)\n",
    "    huffman_codeA, huffman_trA = encoding_huffman(rleA)\n",
    "    \n",
    "    if not huffman_codeA:\n",
    "      print(ligneA)\n",
    "      print(result11A)\n",
    "      \n",
    "    huffman_trsA.append(huffman_trA)\n",
    "    dataA.append(huffman_codeA)\n",
    "  \n",
    "  encoded_dataA, alphabetA, tailleA = encoding_lzw(dataA, color_paletteA)\n",
    "    \n",
    "  return encoded_dataA, alphabetA, tailleA, huffman_trsA, shapeTA, shapetA, mean_valueA, mapped_indicesA, color_paletteA, palette_indicesA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediaireD(encoded_dataB, alphabetB, tailleB, huffman_trB, shapeTB, shapetB, mean_valueB, mapped_indicesB, color_paletteB, palette_indicesB):\n",
    "  resultB = decoding_lzw(encoded_dataB, alphabetB, tailleB)\n",
    "  codesB = []\n",
    "\n",
    "  for i in range(len(resultB)):\n",
    "    vect1B = decoding_huffman(resultB[i], huffman_trB[i])\n",
    "    rleB = rle_decode(vect1B)\n",
    "    matB = inverse_ligne_scan(rleB, shapetB)\n",
    "    quantB = dequantization_mean(matB, mean_valueB)\n",
    "    dctB = inverse_dct(quantB)\n",
    "    subsapB = inverse_sous_echantillonnage_4_2_0(dctB)\n",
    "    codesB.append(subsapB)\n",
    "  \n",
    "  code7 = reconstitution2D(codesB, shapeTB)\n",
    "  mapp = inverse_map_to_palette(mapped_indicesB, color_paletteB)\n",
    "  imageB = inverse_kmeans_clustering_palette(color_paletteB, palette_indicesB)\n",
    "  return imageB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $intermediaire$ $pour$ $la$ $création$ $de$ $la$ $partie$ $\"header\"$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_header(path, num_colors):\n",
    "  image = Image.open(path)\n",
    "  return intermediaireC(image, num_colors)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Création$ $de$ $la$ $partie$ $\"data\"$ $(donnée)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_irm(path, num_colors):\n",
    "  image = Image.open(path)\n",
    "  return intermediaireC(image, num_colors)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Création$ $de$ $la$ $partie$ $\"header\"$ $(entête)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_irm(path, num_colors):\n",
    "    alphabet, taille, huffman_trT, shapeT, shapet, mean_value, mapped_indices, color_palette, palette_indices = create_header(path, num_colors)\n",
    "    header = f\"alphabet: {alphabet}\\n\"\n",
    "    header += f\"taille: {taille}\\n\"\n",
    "    header += f\"huffman_trT: {huffman_trT}\\n\"\n",
    "    header += f\"shapeT: {shapeT}\\n\"\n",
    "    header += f\"shapet: {shapet}\\n\"\n",
    "    header += f\"mean_value: {mean_value}\\n\"\n",
    "    header += f\"mapped_indices: {list(map(list,list(mapped_indices)))}\\n\"\n",
    "    header += f\"color_palette: {list(map(list,list(color_palette)))}\\n\"\n",
    "    header += f\"palette_indices: {list(map(list,list(palette_indices)))}\\n\"\n",
    "    return header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compression_irm(path1, num_colors, path2):\n",
    "    header = header_irm(path1, num_colors)\n",
    "    data = data_irm(path1, num_colors)\n",
    "    compressed_data = \"\\n\".join(str(nombre) for nombre in data)\n",
    "    with open(path2, 'w') as f:\n",
    "        f.write(header)\n",
    "        f.write(compressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Fonction$ $de$ $décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompression_irm(path1, path2):\n",
    "    with open(path1, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        numeric_lines = [line.strip() for line in lines if re.match(r'^\\d+$', line.strip())]\n",
    "        encoded_data = [int(nombre.strip()) for nombre in numeric_lines]\n",
    "        alphabet = np.array(eval(lines[0].split(': ')[1]))\n",
    "        taille = np.array(eval(lines[1].split(': ')[1]))\n",
    "        huffman_trT = eval(lines[2].split(': ')[1])\n",
    "        shapeT = eval(lines[3].split(': ')[1])\n",
    "        shapet = eval(lines[4].split(': ')[1])\n",
    "        mean_value = eval(lines[5].split(': ')[1]) \n",
    "        mapped_indices = np.array(eval(lines[6].split(': ')[1]))\n",
    "        color_palette = np.array(eval(lines[7].split(': ')[1]))\n",
    "        palette_indices = np.array(eval(lines[8].split(': ')[1]))\n",
    "    \n",
    "    image = intermediaireD(encoded_data, alphabet, taille, huffman_trT, shapeT, shapet, mean_value, mapped_indices, color_palette, palette_indices)\n",
    "    image.save(path2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $APPLICATION$ $COMPLÈTE$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/issa-sangare/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home/issa-sangare/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "compression_irm(path, num_colors, path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Décompression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecompression_irm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[169], line 16\u001b[0m, in \u001b[0;36mdecompression_irm\u001b[0;34m(path1, path2)\u001b[0m\n\u001b[1;32m     13\u001b[0m     color_palette \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28meval\u001b[39m(lines[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     14\u001b[0m     palette_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28meval\u001b[39m(lines[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mintermediaireD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphabet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtaille\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuffman_trT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapeT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_palette\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpalette_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m image\u001b[38;5;241m.\u001b[39msave(path2)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "Cell \u001b[0;32mIn[168], line 7\u001b[0m, in \u001b[0;36mintermediaireD\u001b[0;34m(encoded_dataB, alphabetB, tailleB, huffman_trB, shapeTB, shapetB, mean_valueB, mapped_indicesB, color_paletteB, palette_indicesB)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(resultB)):\n\u001b[1;32m      6\u001b[0m   vect1B \u001b[38;5;241m=\u001b[39m decoding_huffman(resultB[i], huffman_trB[i])\n\u001b[0;32m----> 7\u001b[0m   rleB \u001b[38;5;241m=\u001b[39m \u001b[43mrle_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect1B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   matB \u001b[38;5;241m=\u001b[39m inverse_ligne_scan(rleB, shapetB)\n\u001b[1;32m      9\u001b[0m   quantB \u001b[38;5;241m=\u001b[39m dequantization_mean(matB, mean_valueB)\n",
      "Cell \u001b[0;32mIn[146], line 13\u001b[0m, in \u001b[0;36mrle_decode\u001b[0;34m(encoded_data)\u001b[0m\n\u001b[1;32m     11\u001b[0m     decoded_data\u001b[38;5;241m.\u001b[39mextend([char] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mint\u001b[39m(count))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     char \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m char\u001b[38;5;241m.\u001b[39mis_integer():\n\u001b[1;32m     15\u001b[0m         char \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(char)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "decompression_irm(path1, path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Affichage$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = Image.open(path)\n",
    "img2 = Image.open(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Mean$ $Square$ $Error$ $(MSE):$ $Erreur$ $Quadratique$ $Moyenne$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur = MSE(img1, img2)\n",
    "print(f\"L'erreur quadratique moyenne (MSE) est: {erreur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $Taux$ $de$ $compression$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reconstiued3.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m taux \u001b[38;5;241m=\u001b[39m \u001b[43mtaux_compression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaux de compression: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mtaux\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mtaux_compression\u001b[0;34m(img_path, compressed_file_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m img_data_size \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m img\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m pixel_size \u001b[38;5;241m*\u001b[39m pixel_bits  \u001b[38;5;66;03m# Taille en bits de l'image\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Lecture des données compressées à partir du fichier .irm\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompressed_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     compressed_data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     20\u001b[0m compressed_data_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(compressed_data) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# Taille des données compressées en bits\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reconstiued3.jpg'"
     ]
    }
   ],
   "source": [
    "taux = taux_compression(path, path2)\n",
    "print(f\"Taux de compression: {100 * taux} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def duplicate_border(matrix):\n",
    "    # Récupération des dimensions de la matrice d'origine\n",
    "    rows, cols = matrix.shape\n",
    "    \n",
    "    # Création d'une nouvelle matrice avec des dimensions augmentées pour accueillir les bords dupliqués\n",
    "    duplicated_matrix = np.zeros((rows + 2, cols + 2), dtype=matrix.dtype)\n",
    "    \n",
    "    # Copie des valeurs de la matrice d'origine dans la nouvelle matrice\n",
    "    duplicated_matrix[1:rows+1, 1:cols+1] = matrix\n",
    "    \n",
    "    # Duplication des bords horizontaux\n",
    "    duplicated_matrix[0, 1:cols+1] = matrix[0, :]\n",
    "    duplicated_matrix[rows+1, 1:cols+1] = matrix[rows-1, :]\n",
    "    \n",
    "    # Duplication des bords verticaux\n",
    "    duplicated_matrix[1:rows+1, 0] = matrix[:, 0]\n",
    "    duplicated_matrix[1:rows+1, cols+1] = matrix[:, cols-1]\n",
    "    \n",
    "    # Duplication des coins\n",
    "    duplicated_matrix[0, 0] = matrix[0, 0]\n",
    "    duplicated_matrix[0, cols+1] = matrix[0, cols-1]\n",
    "    duplicated_matrix[rows+1, 0] = matrix[rows-1, 0]\n",
    "    duplicated_matrix[rows+1, cols+1] = matrix[rows-1, cols-1]\n",
    "    \n",
    "    return duplicated_matrix\n",
    "\n",
    "# Exemple d'utilisation\n",
    "original_matrix = np.array([\n",
    "    [1,  2,  3,  4,  5,  6,  7,  8],\n",
    "    [9,  10, 11, 12, 13, 14, 15, 16],\n",
    "    [17, 18, 19, 20, 21, 22, 23, 24],\n",
    "    [25, 26, 27, 28, 29, 30, 31, 32],\n",
    "    [33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    [41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    [49, 50, 51, 52, 53, 54, 55, 56],\n",
    "    [57, 58, 59, 60, 61, 62, 63, 64]\n",
    "])\n",
    "\n",
    "duplicated_matrix = duplicate_border(original_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2,  3,  4,  5,  6,  7,  8,  8],\n",
       "       [ 1,  1,  2,  3,  4,  5,  6,  7,  8,  8],\n",
       "       [ 9,  9, 10, 11, 12, 13, 14, 15, 16, 16],\n",
       "       [17, 17, 18, 19, 20, 21, 22, 23, 24, 24],\n",
       "       [25, 25, 26, 27, 28, 29, 30, 31, 32, 32],\n",
       "       [33, 33, 34, 35, 36, 37, 38, 39, 40, 40],\n",
       "       [41, 41, 42, 43, 44, 45, 46, 47, 48, 48],\n",
       "       [49, 49, 50, 51, 52, 53, 54, 55, 56, 56],\n",
       "       [57, 57, 58, 59, 60, 61, 62, 63, 64, 64],\n",
       "       [57, 57, 58, 59, 60, 61, 62, 63, 64, 64]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def duplicate_border(matrix, border_size):\n",
    "    # Récupération des dimensions de la matrice d'origine\n",
    "    rows, cols = matrix.shape\n",
    "    \n",
    "    # Création d'une nouvelle matrice avec des dimensions augmentées pour accueillir les bords dupliqués\n",
    "    duplicated_rows = rows + 2 * border_size\n",
    "    duplicated_cols = cols + 2 * border_size\n",
    "    duplicated_matrix = np.zeros((duplicated_rows, duplicated_cols), dtype=matrix.dtype)\n",
    "    \n",
    "    # Copie des valeurs de la matrice d'origine dans la nouvelle matrice\n",
    "    duplicated_matrix[border_size:border_size+rows, border_size:border_size+cols] = matrix\n",
    "    \n",
    "    # Duplication des bords horizontaux\n",
    "    duplicated_matrix[:border_size, border_size:border_size+cols] = matrix[0, :]  # Bord supérieur\n",
    "    duplicated_matrix[border_size+rows: border_size*2 + rows, border_size:border_size+cols] = matrix[-1, :]  # Bord inférieur\n",
    "    \n",
    "    # Duplication des bords verticaux\n",
    "    duplicated_matrix[border_size:border_size+rows, :border_size] = matrix[:, 0].reshape(-1, 1)  # Bord gauche\n",
    "    duplicated_matrix[border_size:border_size+rows, border_size+cols:border_size*2+cols] = matrix[:, -1].reshape(-1, 1)  # Bord droit\n",
    "    \n",
    "    # Duplication des coins\n",
    "    duplicated_matrix[:border_size, :border_size] = matrix[0, 0]  # Coin supérieur gauche\n",
    "    duplicated_matrix[:border_size, border_size+cols:border_size*2+cols] = matrix[0, -1]  # Coin supérieur droit\n",
    "    duplicated_matrix[border_size+rows: border_size*2+rows, :border_size] = matrix[-1, 0]  # Coin inférieur gauche\n",
    "    duplicated_matrix[border_size+rows: border_size*2+rows, border_size+cols:border_size*2+cols] = matrix[-1, -1]  # Coin inférieur droit\n",
    "    \n",
    "    return duplicated_matrix\n",
    "\n",
    "# Exemple d'utilisation\n",
    "original_matrix = np.array([\n",
    "    [1,  2,  3,  4,  5,  6,  7,  8],\n",
    "    [9,  10, 11, 12, 13, 14, 15, 16],\n",
    "    [17, 18, 19, 20, 21, 22, 23, 24],\n",
    "    [25, 26, 27, 28, 29, 30, 31, 32],\n",
    "    [33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    [41, 42, 43, 44, 45, 46, 47, 48],\n",
    "    [49, 50, 51, 52, 53, 54, 55, 56],\n",
    "    [57, 58, 59, 60, 61, 62, 63, 64]\n",
    "])\n",
    "\n",
    "border_size = 4  # Taille supplémentaire pour les bords\n",
    "\n",
    "duplicated_matrix = duplicate_border(original_matrix, border_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  8,  8],\n",
       "       [ 1,  1,  1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  8,  8],\n",
       "       [ 1,  1,  1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  8,  8],\n",
       "       [ 1,  1,  1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  8,  8],\n",
       "       [ 1,  1,  1,  1,  1,  2,  3,  4,  5,  6,  7,  8,  8,  8,  8,  8],\n",
       "       [ 9,  9,  9,  9,  9, 10, 11, 12, 13, 14, 15, 16, 16, 16, 16, 16],\n",
       "       [17, 17, 17, 17, 17, 18, 19, 20, 21, 22, 23, 24, 24, 24, 24, 24],\n",
       "       [25, 25, 25, 25, 25, 26, 27, 28, 29, 30, 31, 32, 32, 32, 32, 32],\n",
       "       [33, 33, 33, 33, 33, 34, 35, 36, 37, 38, 39, 40, 40, 40, 40, 40],\n",
       "       [41, 41, 41, 41, 41, 42, 43, 44, 45, 46, 47, 48, 48, 48, 48, 48],\n",
       "       [49, 49, 49, 49, 49, 50, 51, 52, 53, 54, 55, 56, 56, 56, 56, 56],\n",
       "       [57, 57, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64],\n",
       "       [57, 57, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64],\n",
       "       [57, 57, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64],\n",
       "       [57, 57, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64],\n",
       "       [57, 57, 57, 57, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_border(matrix):\n",
    "    # Dimensions de la matrice\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "\n",
    "    # Matrice résultante avec une taille supplémentaire pour les bords répétés\n",
    "    wrapped_matrix = [[0] * (cols + 2) for _ in range(rows + 2)]\n",
    "\n",
    "    # Copie des valeurs de la matrice d'origine au centre de la matrice résultante\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            wrapped_matrix[i + 1][j + 1] = matrix[i][j]\n",
    "\n",
    "    # Répétition des bords de la matrice d'origine\n",
    "    for i in range(rows):\n",
    "        wrapped_matrix[i + 1][0] = matrix[i][-1]  # Copie de la dernière colonne à gauche de la première colonne\n",
    "        wrapped_matrix[i + 1][-1] = matrix[i][0]  # Copie de la première colonne à droite de la dernière colonne\n",
    "\n",
    "    # Répétition des bords supérieur et inférieur de la matrice d'origine\n",
    "    wrapped_matrix[0] = wrapped_matrix[-2]  # Copie de la dernière ligne en haut de la première ligne\n",
    "    wrapped_matrix[-1] = wrapped_matrix[1]  # Copie de la première ligne en bas de la dernière ligne\n",
    "\n",
    "    return np.array(wrapped_matrix)\n",
    "\n",
    "# Matrice d'exemple 8x8\n",
    "matrix = np.array([\n",
    "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "       [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "       [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "       [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "       [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "       [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "       [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "       [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])\n",
    "\n",
    "# Application de l'effet de bord d'enroulement\n",
    "result1 = wrap_border(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 57, 58, 59, 60, 61, 62, 63, 64, 57],\n",
       "       [ 8,  1,  2,  3,  4,  5,  6,  7,  8,  1],\n",
       "       [16,  9, 10, 11, 12, 13, 14, 15, 16,  9],\n",
       "       [24, 17, 18, 19, 20, 21, 22, 23, 24, 17],\n",
       "       [32, 25, 26, 27, 28, 29, 30, 31, 32, 25],\n",
       "       [40, 33, 34, 35, 36, 37, 38, 39, 40, 33],\n",
       "       [48, 41, 42, 43, 44, 45, 46, 47, 48, 41],\n",
       "       [56, 49, 50, 51, 52, 53, 54, 55, 56, 49],\n",
       "       [64, 57, 58, 59, 60, 61, 62, 63, 64, 57],\n",
       "       [ 8,  1,  2,  3,  4,  5,  6,  7,  8,  1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def wrap_border(matrix, num_blocs):\n",
    "    if num_blocs == 16:\n",
    "      border_size = int(matrix.shape[0] / 2)\n",
    "      # Dimensions de la matrice d'origine\n",
    "      rows, cols = matrix.shape\n",
    "\n",
    "      # Matrice résultante avec une taille supplémentaire pour les bords répétés\n",
    "      wrapped_rows = rows + 2 * border_size\n",
    "      wrapped_cols = cols + 2 * border_size\n",
    "      wrapped_matrix = np.zeros((wrapped_rows, wrapped_cols), dtype=matrix.dtype)\n",
    "\n",
    "      # Copie des valeurs de la matrice d'origine au centre de la matrice résultante\n",
    "      wrapped_matrix[border_size:border_size + rows, border_size:border_size + cols] = matrix\n",
    "\n",
    "      # Répétition des bords de la matrice d'origine\n",
    "      wrapped_matrix[:border_size, border_size:border_size + cols] = matrix[-border_size:, :]  # Bord supérieur\n",
    "      wrapped_matrix[-border_size:, border_size:border_size + cols] = matrix[:border_size, :]  # Bord inférieur\n",
    "      wrapped_matrix[border_size:border_size + rows, :border_size] = matrix[:, -border_size:]  # Bord gauche\n",
    "      wrapped_matrix[border_size:border_size + rows, -border_size:] = matrix[:, :border_size]  # Bord droit\n",
    "\n",
    "      # Coins\n",
    "      wrapped_matrix[:border_size, :border_size] = matrix[-border_size:, -border_size:]  # Coin supérieur gauche\n",
    "      wrapped_matrix[:border_size, -border_size:] = matrix[-border_size:, :border_size]   # Coin supérieur droit\n",
    "      wrapped_matrix[-border_size:, :border_size] = matrix[:border_size, -border_size:]   # Coin inférieur gauche\n",
    "      wrapped_matrix[-border_size:, -border_size:] = matrix[:border_size, :border_size]    # Coin inférieur droit\n",
    "\n",
    "      return wrapped_matrix\n",
    "    else:\n",
    "      return matrix\n",
    "\n",
    "# Matrice d'exemple 8x8\n",
    "#matrix = np.random.randint(0, 256, size=(8, 8))\n",
    "matrix = np.array([\n",
    "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "       [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "       [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "       [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "       [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "       [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "       [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "       [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "])\n",
    "\n",
    "# Application de l'effet de bord d'enroulement avec la taille de bordure spécifiée\n",
    "result = wrap_border(matrix, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice enveloppée :\n",
      " [[ 68 109 103  77  18  22  37  56  68 109 103  77  18  22  37  56]\n",
      " [ 81 104 113  92  24  35  55  64  81 104 113  92  24  35  55  64]\n",
      " [103 121 120 101  49  64  78  87 103 121 120 101  49  64  78  87]\n",
      " [112 100 103  99  72  92  95  98 112 100 103  99  72  92  95  98]\n",
      " [ 24  40  51  61  16  11  10  16  24  40  51  61  16  11  10  16]\n",
      " [ 26  58  60  55  12  12  14  19  26  58  60  55  12  12  14  19]\n",
      " [ 40  57  69  56  14  13  16  24  40  57  69  56  14  13  16  24]\n",
      " [ 51  87  80  62  14  17  22  29  51  87  80  62  14  17  22  29]\n",
      " [ 68 109 103  77  18  22  37  56  68 109 103  77  18  22  37  56]\n",
      " [ 81 104 113  92  24  35  55  64  81 104 113  92  24  35  55  64]\n",
      " [103 121 120 101  49  64  78  87 103 121 120 101  49  64  78  87]\n",
      " [112 100 103  99  72  92  95  98 112 100 103  99  72  92  95  98]\n",
      " [ 24  40  51  61  16  11  10  16  24  40  51  61  16  11  10  16]\n",
      " [ 26  58  60  55  12  12  14  19  26  58  60  55  12  12  14  19]\n",
      " [ 40  57  69  56  14  13  16  24  40  57  69  56  14  13  16  24]\n",
      " [ 51  87  80  62  14  17  22  29  51  87  80  62  14  17  22  29]]\n",
      "\n",
      "Matrice restaurée :\n",
      " [[16, 11, 10, 16, 24, 40, 51, 61], [12, 12, 14, 19, 26, 58, 60, 55], [14, 13, 16, 24, 40, 57, 69, 56], [14, 17, 22, 29, 51, 87, 80, 62], [18, 22, 37, 56, 68, 109, 103, 77], [24, 35, 55, 64, 81, 104, 113, 92], [49, 64, 78, 87, 103, 121, 120, 101], [72, 92, 95, 98, 112, 100, 103, 99]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unwrap_border(wrapped_matrix, num_blocs):\n",
    "    if num_blocs == 16:\n",
    "        # Vérification que la matrice a la bonne taille\n",
    "        if len(wrapped_matrix) != 16 or len(wrapped_matrix[0]) != 16:\n",
    "            raise ValueError(\"La matrice doit être de taille 16x16\")\n",
    "        \n",
    "        # Création de la matrice résultante de taille 8x8\n",
    "        matrice_reduite = [[0] * 8 for _ in range(8)]\n",
    "        \n",
    "        # Parcours de la matrice 16x16 et copie des éléments pertinents dans la matrice réduite\n",
    "        for i in range(4, 12):\n",
    "            for j in range(4, 12):\n",
    "                matrice_reduite[i-4][j-4] = wrapped_matrix[i][j]\n",
    "        \n",
    "        return matrice_reduite\n",
    "    else:\n",
    "        return wrapped_matrix\n",
    "\n",
    "# Création d'une matrice de test\n",
    "matrix = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "                                  [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "                                  [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "                                  [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "                                  [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "                                  [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "                                  [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "                                  [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "\n",
    "# Envelopper les bords de la matrice\n",
    "wrapped_matrix = wrap_border(matrix, 16)\n",
    "print(\"Matrice enveloppée :\\n\", wrapped_matrix)\n",
    "\n",
    "# Restaurer la matrice d'origine\n",
    "restored_matrix = unwrap_border(wrapped_matrix, 16)\n",
    "print(\"\\nMatrice restaurée :\\n\", restored_matrix)\n",
    "print((matrix == restored_matrix).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecteur original : [-3.5  2.   1.5 -4.   3.  -2.5]\n",
      "Vecteur quantifié : [  71.  857.  785.    0. 1000.  214.]\n",
      "Vecteur dequantifié : [-3.503  1.999  1.495 -4.     3.    -2.502]\n",
      "Chaîne compressée : 10000101110001011100011110000010110111110111001111111011110101001101000111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def quantize_vector(vector, num_intervals):\n",
    "    min_val = min(vector)\n",
    "    max_val = max(vector)\n",
    "    interval_size = (max_val - min_val) / num_intervals\n",
    "    quantized_vector = np.floor((vector - min_val) / interval_size)\n",
    "    return quantized_vector, min_val, interval_size\n",
    "\n",
    "def dequantize_vector(quantized_vector, min_val, interval_size):\n",
    "    return quantized_vector * interval_size + min_val\n",
    "\n",
    "def ext_chr(chaine):\n",
    "    occ = {c: chaine.count(c) for c in set(chaine)}\n",
    "    return sorted(occ.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def huffman_dictionnary_code(node, binString=''):\n",
    "    if isinstance(node, str):\n",
    "        return {node: binString}\n",
    "    (l, r) = node\n",
    "    d = {}\n",
    "    d.update(huffman_dictionnary_code(l, binString + '0'))\n",
    "    d.update(huffman_dictionnary_code(r, binString + '1'))\n",
    "    return d\n",
    "\n",
    "def huffman_tree(chaine):\n",
    "    nodes = ext_chr(chaine)\n",
    "    \n",
    "    while len(nodes) > 1:\n",
    "        (key1, c1) = nodes.pop()\n",
    "        (key2, c2) = nodes.pop()\n",
    "        node = (key1, key2)\n",
    "        nodes.append((node, c1 + c2))\n",
    "        nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "    return nodes[0][0]\n",
    "\n",
    "def encoding_huffman(strings):\n",
    "    huffman_tree_result = huffman_tree(strings)  # Stockez l'arbre de Huffman dans une variable distincte\n",
    "    huffmanCode = huffman_dictionnary_code(huffman_tree_result)\n",
    "    compressed_string = ''\n",
    "    \n",
    "    for char in strings:\n",
    "        compressed_string += huffmanCode[char]\n",
    "        \n",
    "    return compressed_string, huffman_tree_result\n",
    "\n",
    "def decoding_huffman(compressed_string, huffman_tree):\n",
    "    decoded_string = ''\n",
    "    current_node = huffman_tree\n",
    "    \n",
    "    for bit in compressed_string:\n",
    "        if bit == '0':\n",
    "            current_node = current_node[0]\n",
    "        else:\n",
    "            current_node = current_node[1]\n",
    "        \n",
    "        if isinstance(current_node, str):\n",
    "            decoded_string += current_node\n",
    "            current_node = huffman_tree\n",
    "    \n",
    "    return decoded_string\n",
    "\n",
    "# Exemple de vecteur de valeurs float64\n",
    "vector = np.array([-3.5, 2.0, 1.5, -4.0, 3.0, -2.5])\n",
    "\n",
    "# Paramètres de quantification\n",
    "num_intervals = 1000\n",
    "\n",
    "# Quantification du vecteur\n",
    "quantized_vector, min_val, interval_size = quantize_vector(vector, num_intervals)\n",
    "dequantized_vector = dequantize_vector(quantized_vector, min_val, interval_size)\n",
    "\n",
    "print(\"Vecteur original :\", vector)\n",
    "print(\"Vecteur quantifié :\", quantized_vector)\n",
    "print(\"Vecteur dequantifié :\", dequantized_vector)\n",
    "\n",
    "# Convertir le vecteur quantifié en chaîne de caractères\n",
    "quantized_string = ''.join(map(str, quantized_vector))\n",
    "\n",
    "# Appliquer l'algorithme de Huffman\n",
    "compressed_string, huffman_tree_result = encoding_huffman(quantized_string)\n",
    "\n",
    "# Imprimer la chaîne compressée\n",
    "print(\"Chaîne compressée :\", compressed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaîne de caractères: -1236780\n",
      "Tailles des éléments int64: [3, 3, 1]\n",
      "Vecteur reconstruit: [-12. 367.   8.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Génération d'un vecteur aléatoire de taille 64 avec des valeurs float64\n",
    "vector = np.random.rand(64) * 100 - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste transformée en chaîne: 1-23-45\n",
      "Chaîne transformée en liste: [1, -2, 3, -4, 5]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def list_to_string(lst):\n",
    "    # Convertit chaque nombre en chaîne de caractères et les joint avec des virgules\n",
    "    string = ''.join(str(num) for num in lst.tolist())\n",
    "    lengths = [len(str(i)) for i in lst.tolist()]\n",
    "    \n",
    "    return string, lengths\n",
    "\n",
    "def string_to_list(string, lengths):\n",
    "    start = 0\n",
    "    lst = []\n",
    "    for length in lengths:\n",
    "        num_str = string[start:start+length]\n",
    "        lst.append(int(num_str))\n",
    "        start += length\n",
    "    return lst\n",
    "\n",
    "# Exemple d'utilisation\n",
    "liste = np.array([1, -2, 3, -4, 5])\n",
    "chaine, lengths = list_to_string(liste)\n",
    "print(\"Liste transformée en chaîne:\", chaine)\n",
    "\n",
    "nouvelle_liste = string_to_list(chaine, lengths)\n",
    "print(\"Chaîne transformée en liste:\", nouvelle_liste)\n",
    "print((liste == nouvelle_liste).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
